{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eun-woo/seq2seq/blob/main/style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3c4gYFo_xxV",
        "outputId": "4a16329d-bc96-42b1-9ff2-1a3650debeb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Sep 13 16:59:38 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    27W /  70W |   1318MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsNDAu9HCZ3U",
        "outputId": "4614ba4f-c8e3-4e71-a013-7dabbd94f078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "--2022-09-13 16:59:41--  https://raw.githubusercontent.com/smilegate-ai/korean_smile_style_dataset/main/smilestyle_dataset.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2357401 (2.2M) [text/plain]\n",
            "Saving to: ‘smilestyle_dataset.tsv.1’\n",
            "\n",
            "smilestyle_dataset. 100%[===================>]   2.25M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-09-13 16:59:41 (236 MB/s) - ‘smilestyle_dataset.tsv.1’ saved [2357401/2357401]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!wget https://raw.githubusercontent.com/smilegate-ai/korean_smile_style_dataset/main/smilestyle_dataset.tsv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godUPwK1EKZ6",
        "outputId": "0f7cf29f-1381-491a-a163-d8eca891030a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive2; to attempt to forcibly remount, call drive.mount(\"/content/drive2\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh8X4n_cDB22"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    AutoTokenizer,\n",
        "    Seq2SeqTrainingArguments,\n",
        "    Seq2SeqTrainer,\n",
        "    DataCollatorForSeq2Seq,\n",
        ")\n",
        "from tokenizers import Tokenizer\n",
        "from typing import Dict, List, Optional\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from IPython.display import display\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7L1fJcf5JKc",
        "outputId": "04d89f5f-1f12-4605-b3a9-fe059de3c260"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3470, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df = pd.read_csv(\"smilestyle_dataset.tsv\", sep='\\t')\n",
        "df_notna = df.notna().sum(axis=1)\n",
        "\n",
        "#df = df[df_notna>=2]\n",
        "\n",
        "df = df.dropna(thresh=2)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmkkp-0G0N_y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "9ENwwOrwDLnV",
        "outputId": "3a132e19-5bc0-4c7b-ac4f-032c437c62e1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        formal                    informal  \\\n",
              "0       안녕하세요. 저는 고양이 6마리 키워요.          안녕! 나는 고양이 6마리 키워.   \n",
              "1     고양이를 6마리나요? 키우는거 안 힘드세요?      고양이를 6마리나? 키우는거 안 힘들어?   \n",
              "2  제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.  내가 워낙 고양이를 좋아해서 크게 힘들진 않아.   \n",
              "3       가장 나이가 많은 고양이가 어떻게 돼요?       가장 나이가 많은 고양이가 몇 살이야?   \n",
              "4           여섯 살입니다. 갈색 고양이에요.            여섯 살이야. 갈색 고양이지.   \n",
              "\n",
              "                           android                                   azae  \\\n",
              "0  휴먼. 반갑다. 안드로이드는. 고양이. 6마리. 소유중.  아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여   \n",
              "1             고양이. 6마리. 양육. 번거로운가.        아니 무슨 고양이를 6마리나? 거 키우는 거 안 힘든가?   \n",
              "2         안드로이드. 고양이. 선호. 힘들지. 않음.        내가 또 워~낙에 고양이를 좋아해서 크게 뭐 힘들진 않고   \n",
              "3           제일. 나이많은. 고양이. 나이. 무엇.                그려 가장 나이가 많은 고양이가 몇살이여?   \n",
              "4                    고양이. 갈색. 여섯살.                        6살인데 갈색 고양이 있어~   \n",
              "\n",
              "                     chat                 choding  \\\n",
              "0     하잉ㅋㅋ 나 떼걸룩 6마리 키운다!      ㅎㅇ 나 주인님 6마리 모심 ㅋㅋ   \n",
              "1       엥? 6마리나? 안힘듬?ㅋㅋㅋㅋ        6마리? 에바아니냐 안 힘듦?   \n",
              "2  내가 고양이 좋아해서 딱히 안힘듬 ㅋㅋㅋ  ㄱㅊ 나 고양이 환장해서 힘든 것도 모름   \n",
              "3     가장 나이 먹은 고양이가 몇살이야?         젤 낡은 고영희가 몇 살임?   \n",
              "4        이제 여섯살이고 갈색고양이임!                 6살, 갈색임   \n",
              "\n",
              "                                  emoticon  \\\n",
              "0        안녕!! >< 나는 고양이😺를 ➏ 마리 키우고있어!! 0_0   \n",
              "1  고양이를 6마리나?!! w(ﾟДﾟ)w 키우는거 안 힘듬?? (⊙_⊙;)   \n",
              "2    뭐 나야 워낙에 고양이 좋아하니까 딱히 안힘드엉! \\(@^0^@)/   \n",
              "3             가장 나이 먹은 고양인 몇 살이양? (´･ω･`)?   \n",
              "4           여설 살!! ㄱ^o^/ 색깔은 갈색! O(*￣▽￣*)ブ   \n",
              "\n",
              "                                       enfp                        gentle  \\\n",
              "0           안녕안녕~! 나 고양이 6마리나 키운다? 완전 대박이징~     안녕하십니까,, 저는 고양이 6마리 키웁니다.   \n",
              "1           고양이를 6마리나? 완전 대박~ 키우는 거 안 힘들어?!     고양이를 6마리나 키우십니까? 안 힘드신지,,   \n",
              "2  내가 또 워~낙에 고양이를 좋아하잖아~ 그렇게 크~게 힘들진 않아 ㅎㅎ~  제가 워낙 고양이를 좋아해서 크게 힘들진 않습니다.   \n",
              "3    대박대박 완전 대박!! 그럼 제~일 나이 많은 고양이는 몇살이야~?!         가장 나이가 있는 고양이가 몇살입니까?   \n",
              "4     6살인 애 있는데, 완전 귀.여.워. 갈색 고양이야 진짜 대박이지?              6살된 갈색 아이가 있습니다.   \n",
              "\n",
              "                                halbae                       halmae  \\\n",
              "0      안녕하신가~... 난 지금 고양이를 6마리 키우고 있다네  하유 시벌것 괭이놈 6마리 키우는데 힘들어 죽겟네   \n",
              "1             고양이를 6마리나? 키우는거 힘들지 않는가?      니기럴 털만 날리는 거 키우기 안 힘들데?   \n",
              "2  내가 워낙에...고양이가 좋아가지고 그렇게 힘들지 않어...^^         옘병 내가 좋아하니까 키워야지 시벌것   \n",
              "3        고양이들 중에서…가장 나이 먹을 애가 몇살인가?...     거 젤 빨리 뒤질 놈이 나이 얼마나 쳐먹었냐   \n",
              "4                  저…갈색 고양이인데…여섯살이지~..   저 노망난 갈색놈이 6살 뒤룩뒤룩 쳐먹은 놈이여   \n",
              "\n",
              "                   joongding                         king  \\\n",
              "0  안녕하냐 ㅡㅡ 나 씹냥이 6마리나 키운다 하;       반갑소. 짐은 고양이를 6마리나 키우오.   \n",
              "1        아니 고양이를 6마리나? 안힘드냐?    고양이를 6마리나? 키우는게 수고스럽진 않소?   \n",
              "2      고양이 좋아한다고ㅡㅡ 1도 안힘듬 ㅡㅡ  과인은 고양이를 어여삐 어겨 그리 수고스럽진 않소   \n",
              "3               가장 늙은애가 몇살인데        최고령 고양이의 나이는 어떻게 되는가?   \n",
              "4                여섯살 갈색냥인데 왜             여섯 살이오. 갈색 고양이오.   \n",
              "\n",
              "                         naruto                            seonbi  \\\n",
              "0   안녕하냐니깐! 난 고양이를 6마리 키우고있다니깐!       안녕하시오! 소인은 고양이를 6마리 키우고 있소!   \n",
              "1     고양이를 6마리나? 키우는거 힘들지 않냐니깐?     고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?   \n",
              "2  내가 고양이를 엄청 좋아해서 별로 힘들지 않다니깐!  소인 고양이를 엄청 좋아하기 때문에 별로 힘들지 않소이다.   \n",
              "3   가장 나이 많이 먹은 고양이가 몇 살 이냐니깐?!          나이를 가장 많이 먹은 고양이가 몇 살이오?   \n",
              "4              갈색 고양이가 여섯살이라니깐!                     여섯 살에 갈색 고양이오   \n",
              "\n",
              "                                 sosim                     translator  \n",
              "0                  안녕… 난 고양이 6마리 키워 ㅠㅠ     반가운. 나는 6마리의 고양이를 소지하고 있다.  \n",
              "1         고양이..6마리나? ㅠ 키우는건 혹시 안힘들어..?  6마리의 고양이? 당신은 그들로부터 지치지 않습니까?  \n",
              "2  내가 고양이 워낙 좋아해서..ㅠㅠ 크게 힘들진 않은 것 같아..        나는 고양이의 큰 애호가. 지치지 않는다.  \n",
              "3        혹시.. 제일 나이 많은 고양이는.. 몇살이야..?ㅠ             가장 늙은 고양이가 몇 년입니까?  \n",
              "4                여섯살이야.. 갈색 ㅠㅠ 고양이야..ㅠ                 여섯. 고양이는 갈색이다.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a3e857d4-c222-47ad-9164-960f494fb733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>formal</th>\n",
              "      <th>informal</th>\n",
              "      <th>android</th>\n",
              "      <th>azae</th>\n",
              "      <th>chat</th>\n",
              "      <th>choding</th>\n",
              "      <th>emoticon</th>\n",
              "      <th>enfp</th>\n",
              "      <th>gentle</th>\n",
              "      <th>halbae</th>\n",
              "      <th>halmae</th>\n",
              "      <th>joongding</th>\n",
              "      <th>king</th>\n",
              "      <th>naruto</th>\n",
              "      <th>seonbi</th>\n",
              "      <th>sosim</th>\n",
              "      <th>translator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>안녕하세요. 저는 고양이 6마리 키워요.</td>\n",
              "      <td>안녕! 나는 고양이 6마리 키워.</td>\n",
              "      <td>휴먼. 반갑다. 안드로이드는. 고양이. 6마리. 소유중.</td>\n",
              "      <td>아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여</td>\n",
              "      <td>하잉ㅋㅋ 나 떼걸룩 6마리 키운다!</td>\n",
              "      <td>ㅎㅇ 나 주인님 6마리 모심 ㅋㅋ</td>\n",
              "      <td>안녕!! &gt;&lt; 나는 고양이😺를 ➏ 마리 키우고있어!! 0_0</td>\n",
              "      <td>안녕안녕~! 나 고양이 6마리나 키운다? 완전 대박이징~</td>\n",
              "      <td>안녕하십니까,, 저는 고양이 6마리 키웁니다.</td>\n",
              "      <td>안녕하신가~... 난 지금 고양이를 6마리 키우고 있다네</td>\n",
              "      <td>하유 시벌것 괭이놈 6마리 키우는데 힘들어 죽겟네</td>\n",
              "      <td>안녕하냐 ㅡㅡ 나 씹냥이 6마리나 키운다 하;</td>\n",
              "      <td>반갑소. 짐은 고양이를 6마리나 키우오.</td>\n",
              "      <td>안녕하냐니깐! 난 고양이를 6마리 키우고있다니깐!</td>\n",
              "      <td>안녕하시오! 소인은 고양이를 6마리 키우고 있소!</td>\n",
              "      <td>안녕… 난 고양이 6마리 키워 ㅠㅠ</td>\n",
              "      <td>반가운. 나는 6마리의 고양이를 소지하고 있다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>고양이를 6마리나요? 키우는거 안 힘드세요?</td>\n",
              "      <td>고양이를 6마리나? 키우는거 안 힘들어?</td>\n",
              "      <td>고양이. 6마리. 양육. 번거로운가.</td>\n",
              "      <td>아니 무슨 고양이를 6마리나? 거 키우는 거 안 힘든가?</td>\n",
              "      <td>엥? 6마리나? 안힘듬?ㅋㅋㅋㅋ</td>\n",
              "      <td>6마리? 에바아니냐 안 힘듦?</td>\n",
              "      <td>고양이를 6마리나?!! w(ﾟДﾟ)w 키우는거 안 힘듬?? (⊙_⊙;)</td>\n",
              "      <td>고양이를 6마리나? 완전 대박~ 키우는 거 안 힘들어?!</td>\n",
              "      <td>고양이를 6마리나 키우십니까? 안 힘드신지,,</td>\n",
              "      <td>고양이를 6마리나? 키우는거 힘들지 않는가?</td>\n",
              "      <td>니기럴 털만 날리는 거 키우기 안 힘들데?</td>\n",
              "      <td>아니 고양이를 6마리나? 안힘드냐?</td>\n",
              "      <td>고양이를 6마리나? 키우는게 수고스럽진 않소?</td>\n",
              "      <td>고양이를 6마리나? 키우는거 힘들지 않냐니깐?</td>\n",
              "      <td>고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?</td>\n",
              "      <td>고양이..6마리나? ㅠ 키우는건 혹시 안힘들어..?</td>\n",
              "      <td>6마리의 고양이? 당신은 그들로부터 지치지 않습니까?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.</td>\n",
              "      <td>내가 워낙 고양이를 좋아해서 크게 힘들진 않아.</td>\n",
              "      <td>안드로이드. 고양이. 선호. 힘들지. 않음.</td>\n",
              "      <td>내가 또 워~낙에 고양이를 좋아해서 크게 뭐 힘들진 않고</td>\n",
              "      <td>내가 고양이 좋아해서 딱히 안힘듬 ㅋㅋㅋ</td>\n",
              "      <td>ㄱㅊ 나 고양이 환장해서 힘든 것도 모름</td>\n",
              "      <td>뭐 나야 워낙에 고양이 좋아하니까 딱히 안힘드엉! \\(@^0^@)/</td>\n",
              "      <td>내가 또 워~낙에 고양이를 좋아하잖아~ 그렇게 크~게 힘들진 않아 ㅎㅎ~</td>\n",
              "      <td>제가 워낙 고양이를 좋아해서 크게 힘들진 않습니다.</td>\n",
              "      <td>내가 워낙에...고양이가 좋아가지고 그렇게 힘들지 않어...^^</td>\n",
              "      <td>옘병 내가 좋아하니까 키워야지 시벌것</td>\n",
              "      <td>고양이 좋아한다고ㅡㅡ 1도 안힘듬 ㅡㅡ</td>\n",
              "      <td>과인은 고양이를 어여삐 어겨 그리 수고스럽진 않소</td>\n",
              "      <td>내가 고양이를 엄청 좋아해서 별로 힘들지 않다니깐!</td>\n",
              "      <td>소인 고양이를 엄청 좋아하기 때문에 별로 힘들지 않소이다.</td>\n",
              "      <td>내가 고양이 워낙 좋아해서..ㅠㅠ 크게 힘들진 않은 것 같아..</td>\n",
              "      <td>나는 고양이의 큰 애호가. 지치지 않는다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>가장 나이가 많은 고양이가 어떻게 돼요?</td>\n",
              "      <td>가장 나이가 많은 고양이가 몇 살이야?</td>\n",
              "      <td>제일. 나이많은. 고양이. 나이. 무엇.</td>\n",
              "      <td>그려 가장 나이가 많은 고양이가 몇살이여?</td>\n",
              "      <td>가장 나이 먹은 고양이가 몇살이야?</td>\n",
              "      <td>젤 낡은 고영희가 몇 살임?</td>\n",
              "      <td>가장 나이 먹은 고양인 몇 살이양? (´･ω･`)?</td>\n",
              "      <td>대박대박 완전 대박!! 그럼 제~일 나이 많은 고양이는 몇살이야~?!</td>\n",
              "      <td>가장 나이가 있는 고양이가 몇살입니까?</td>\n",
              "      <td>고양이들 중에서…가장 나이 먹을 애가 몇살인가?...</td>\n",
              "      <td>거 젤 빨리 뒤질 놈이 나이 얼마나 쳐먹었냐</td>\n",
              "      <td>가장 늙은애가 몇살인데</td>\n",
              "      <td>최고령 고양이의 나이는 어떻게 되는가?</td>\n",
              "      <td>가장 나이 많이 먹은 고양이가 몇 살 이냐니깐?!</td>\n",
              "      <td>나이를 가장 많이 먹은 고양이가 몇 살이오?</td>\n",
              "      <td>혹시.. 제일 나이 많은 고양이는.. 몇살이야..?ㅠ</td>\n",
              "      <td>가장 늙은 고양이가 몇 년입니까?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>여섯 살입니다. 갈색 고양이에요.</td>\n",
              "      <td>여섯 살이야. 갈색 고양이지.</td>\n",
              "      <td>고양이. 갈색. 여섯살.</td>\n",
              "      <td>6살인데 갈색 고양이 있어~</td>\n",
              "      <td>이제 여섯살이고 갈색고양이임!</td>\n",
              "      <td>6살, 갈색임</td>\n",
              "      <td>여설 살!! ㄱ^o^/ 색깔은 갈색! O(*￣▽￣*)ブ</td>\n",
              "      <td>6살인 애 있는데, 완전 귀.여.워. 갈색 고양이야 진짜 대박이지?</td>\n",
              "      <td>6살된 갈색 아이가 있습니다.</td>\n",
              "      <td>저…갈색 고양이인데…여섯살이지~..</td>\n",
              "      <td>저 노망난 갈색놈이 6살 뒤룩뒤룩 쳐먹은 놈이여</td>\n",
              "      <td>여섯살 갈색냥인데 왜</td>\n",
              "      <td>여섯 살이오. 갈색 고양이오.</td>\n",
              "      <td>갈색 고양이가 여섯살이라니깐!</td>\n",
              "      <td>여섯 살에 갈색 고양이오</td>\n",
              "      <td>여섯살이야.. 갈색 ㅠㅠ 고양이야..ㅠ</td>\n",
              "      <td>여섯. 고양이는 갈색이다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a3e857d4-c222-47ad-9164-960f494fb733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a3e857d4-c222-47ad-9164-960f494fb733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a3e857d4-c222-47ad-9164-960f494fb733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "formal        0.063428\n",
              "informal      0.063428\n",
              "android       0.520918\n",
              "azae          0.723347\n",
              "chat          0.063428\n",
              "choding       0.063428\n",
              "emoticon      0.514980\n",
              "enfp          0.544130\n",
              "gentle        0.540351\n",
              "halbae        0.515789\n",
              "halmae        0.726586\n",
              "joongding     0.063428\n",
              "king          0.520918\n",
              "naruto        0.514980\n",
              "seonbi        0.514980\n",
              "sosim         0.520918\n",
              "translator    0.594062\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        formal informal android                                   azae  chat  \\\n",
              "count     3470     3470    1775                                   1025  3470   \n",
              "unique    3430     3417    1748                                   1025  3437   \n",
              "top     안녕하세요.      안녕.    반갑다.  아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여    하이   \n",
              "freq        23       25      10                                      1    13   \n",
              "\n",
              "       choding      emoticon  enfp  gentle  halbae halmae joongding  king  \\\n",
              "count     3470          1797  1689    1703    1794   1013      3470  1775   \n",
              "unique    3390          1793  1679    1691    1784   1005      3396  1759   \n",
              "top         왜?  안녕! (ﾉ*･ω･)ﾉ   안뇽~  안녕하십니까  안녕하신가…  왜 땜시?        ㅎㅇ  반갑소.   \n",
              "freq        37             3     6       5       8      4        29     7   \n",
              "\n",
              "         naruto  seonbi sosim translator  \n",
              "count      1797    1797  1775       1504  \n",
              "unique     1779    1784  1758       1489  \n",
              "top     안녕하냐니깐!  안녕하시오!  안녕..       반가운.  \n",
              "freq          9       9     9          9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-59771c84-6eb4-4a89-8cd1-2a0f4172483e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>formal</th>\n",
              "      <th>informal</th>\n",
              "      <th>android</th>\n",
              "      <th>azae</th>\n",
              "      <th>chat</th>\n",
              "      <th>choding</th>\n",
              "      <th>emoticon</th>\n",
              "      <th>enfp</th>\n",
              "      <th>gentle</th>\n",
              "      <th>halbae</th>\n",
              "      <th>halmae</th>\n",
              "      <th>joongding</th>\n",
              "      <th>king</th>\n",
              "      <th>naruto</th>\n",
              "      <th>seonbi</th>\n",
              "      <th>sosim</th>\n",
              "      <th>translator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3470</td>\n",
              "      <td>3470</td>\n",
              "      <td>1775</td>\n",
              "      <td>1025</td>\n",
              "      <td>3470</td>\n",
              "      <td>3470</td>\n",
              "      <td>1797</td>\n",
              "      <td>1689</td>\n",
              "      <td>1703</td>\n",
              "      <td>1794</td>\n",
              "      <td>1013</td>\n",
              "      <td>3470</td>\n",
              "      <td>1775</td>\n",
              "      <td>1797</td>\n",
              "      <td>1797</td>\n",
              "      <td>1775</td>\n",
              "      <td>1504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3430</td>\n",
              "      <td>3417</td>\n",
              "      <td>1748</td>\n",
              "      <td>1025</td>\n",
              "      <td>3437</td>\n",
              "      <td>3390</td>\n",
              "      <td>1793</td>\n",
              "      <td>1679</td>\n",
              "      <td>1691</td>\n",
              "      <td>1784</td>\n",
              "      <td>1005</td>\n",
              "      <td>3396</td>\n",
              "      <td>1759</td>\n",
              "      <td>1779</td>\n",
              "      <td>1784</td>\n",
              "      <td>1758</td>\n",
              "      <td>1489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>안녕하세요.</td>\n",
              "      <td>안녕.</td>\n",
              "      <td>반갑다.</td>\n",
              "      <td>아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여</td>\n",
              "      <td>하이</td>\n",
              "      <td>왜?</td>\n",
              "      <td>안녕! (ﾉ*･ω･)ﾉ</td>\n",
              "      <td>안뇽~</td>\n",
              "      <td>안녕하십니까</td>\n",
              "      <td>안녕하신가…</td>\n",
              "      <td>왜 땜시?</td>\n",
              "      <td>ㅎㅇ</td>\n",
              "      <td>반갑소.</td>\n",
              "      <td>안녕하냐니깐!</td>\n",
              "      <td>안녕하시오!</td>\n",
              "      <td>안녕..</td>\n",
              "      <td>반가운.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>23</td>\n",
              "      <td>25</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>37</td>\n",
              "      <td>3</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-59771c84-6eb4-4a89-8cd1-2a0f4172483e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-59771c84-6eb4-4a89-8cd1-2a0f4172483e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-59771c84-6eb4-4a89-8cd1-2a0f4172483e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3705, 17)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"smilestyle_dataset.tsv\", sep=\"\\t\")\n",
        "display(df.head())\n",
        "display(df.isna().mean())\n",
        "display(df.describe())\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "93v8e_rrDQ8W",
        "outputId": "5f23595d-58b5-440d-8654-f6382de4743e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3470\n"
          ]
        }
      ],
      "source": [
        "row_notna_count = df.notna().sum(axis=1)\n",
        "row_notna_count.plot.hist(bins=row_notna_count.max())\n",
        "plt.show()\n",
        "\n",
        "df = df[row_notna_count >= 2]\n",
        "print(len(df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cICV7i_DbPR",
        "outputId": "5dd6f76a-a8b1-4758-decc-06e32e205b27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/54a37e9385f90886428b084042f151c1a699203416d41765d94aac4cddb5fd5c.d098ef3866c1da94bdfaa5c1f24ecb7c5c16b37423b79263fbd3668d2ae61f91\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/f94202e1dad4fcfcb282aff4c6865b6119e03c87c6fa9e5886abe93835c41ecd.dc2013f8bbecd755468e2c44397f53dc624be5451d0190744397caf61a20383f\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/7c75331e2f4b5767db997fbb489f1408eb36a3217beb3057ae8d04bd2b3f97ba.04312f398a3bbda664297588800a86e0fda9d4ef4f0749cd9d96f88043daad39\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/a87d2ed77831bb40ce806a97c04126addf5ecc82b3e23ecf916b2a4acdb9c29a.c23d5e62137984cf842a885705037b25b156747d145406702932d5f5d5e7c88e\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/54a37e9385f90886428b084042f151c1a699203416d41765d94aac4cddb5fd5c.d098ef3866c1da94bdfaa5c1f24ecb7c5c16b37423b79263fbd3668d2ae61f91\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gogamza/kobart-base-v2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "wrdwMrp1De4L",
        "outputId": "afc3da1f-28fe-45e0-848d-bbd101f00b6c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "count    36793.000000\n",
              "mean        13.147582\n",
              "std          6.909344\n",
              "min          1.000000\n",
              "25%          8.000000\n",
              "50%         12.000000\n",
              "75%         17.000000\n",
              "max        318.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff0e9fbbc90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "lengths = []\n",
        "\n",
        "for column in df.columns:\n",
        "  out = tokenizer(df[column][df[column].notna()].tolist())\n",
        "  out = [len(x) for x in out['input_ids']]\n",
        "  lengths.extend(out)\n",
        "\n",
        "lengths = pd.Series(lengths)\n",
        "display(lengths.describe())\n",
        "lengths.plot.hist(bins=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thvEjf6oDj_V"
      },
      "outputs": [],
      "source": [
        "style_map = {\n",
        "    'formal': '문어체',\n",
        "    'informal': '구어체',\n",
        "    'android': '안드로이드',\n",
        "    'azae': '아재',\n",
        "    'chat': '채팅',\n",
        "    'choding': '초등학생',\n",
        "    'emoticon': '이모티콘',\n",
        "    'enfp': 'enfp',\n",
        "    'gentle': '신사',\n",
        "    'halbae': '할아버지',\n",
        "    'halmae': '할머니',\n",
        "    'joongding': '중학생',\n",
        "    'king': '왕',\n",
        "    'naruto': '나루토',\n",
        "    'seonbi': '선비',\n",
        "    'sosim': '소심한',\n",
        "    'translator': '번역기'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IASg5hsjDnOF"
      },
      "outputs": [],
      "source": [
        "class TextStyleTransferDataset(Dataset):\n",
        "  def __init__(self, \n",
        "               df: pd.DataFrame, \n",
        "               tokenizer: Tokenizer\n",
        "               ):\n",
        "    self.df = df\n",
        "    self.tokenizer = tokenizer\n",
        "    \n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    row = self.df.iloc[index, :].dropna().sample(2)\n",
        "    text1 = row[0]\n",
        "    text2 = row[1]\n",
        "    target_style = row.index[1]\n",
        "    target_style_name = style_map[target_style]\n",
        "\n",
        "    encoder_text = f\"{target_style_name} 말투로 변환:{text1}\"\n",
        "    decoder_text = f\"{text2}{self.tokenizer.eos_token}\"\n",
        "    model_inputs = self.tokenizer(encoder_text, max_length=256, truncation=True)\n",
        "\n",
        "    with self.tokenizer.as_target_tokenizer():\n",
        "      labels = tokenizer(decoder_text, max_length=256, truncation=True)\n",
        "    model_inputs['labels'] = labels['input_ids']\n",
        "    del model_inputs['token_type_ids']\n",
        "\n",
        "    return model_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqARnuHmDrQT",
        "outputId": "b4b37b4f-4aff-4e2f-970e-5499260594f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14112, 11763, 12687, 14070, 13282, 10338, 14296, 13716, 257, 11699, 9592, 13586, 25161, 16530, 17849, 12034, 14195, 26832, 18712, 14543]\n",
            "[22465, 232, 14651, 17849, 12034, 14195, 26832, 18712, 245, 1]\n",
            "구어체 말투로 변환:안녕하세요. 저는 고양이 6마리 키워요.\n",
            "안녕! 나는 고양이 6마리 키워.</s>\n",
            "[14081, 19709, 14070, 13282, 10338, 14296, 13716, 257, 9102, 11747, 15188, 14195, 10496, 24665, 14947, 16932, 14082, 14186, 11841, 262, 15994, 12332, 14076, 11319, 262]\n",
            "[17849, 12034, 14176, 253, 10496, 24665, 262, 1700, 1275, 25144, 9034, 20604, 14105, 13848, 17714, 14176, 262, 1]\n",
            "소심한 말투로 변환:고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?\n",
            "고양이..6마리나? ᅲ 키우는건 혹시 안힘들어..?</s>\n"
          ]
        }
      ],
      "source": [
        "dataset = TextStyleTransferDataset(df, tokenizer)\n",
        "out = dataset[0]\n",
        "print(out['input_ids'])\n",
        "print(out['labels'])\n",
        "print(tokenizer.decode(out['input_ids']))\n",
        "print(tokenizer.decode(out['labels']))\n",
        "\n",
        "out = dataset[1]\n",
        "print(out['input_ids'])\n",
        "print(out['labels'])\n",
        "print(tokenizer.decode(out['input_ids']))\n",
        "print(tokenizer.decode(out['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YpifEyh0DuN2",
        "outputId": "4f9f5520-d139-4917-8f49-8d04262e7080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3123 347\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 학습을 위해 train, test set으로 나눈다.\n",
        "df_train, df_test = train_test_split(df, test_size=0.1, random_state=42)\n",
        "print(len(df_train), len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc6fjr6sDxu5",
        "outputId": "42845d10-01be-4823-cfb8-9ca4248e1a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/54a37e9385f90886428b084042f151c1a699203416d41765d94aac4cddb5fd5c.d098ef3866c1da94bdfaa5c1f24ecb7c5c16b37423b79263fbd3668d2ae61f91\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/6a128677efa8d82c5bc9853bbefcff450bf4174bed52765687fc77f1aa7a39c1.ef5977990801f5b7dbc37adda9fe5948ed9829c75ac20e99bf026098743b1978\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at gogamza/kobart-base-v2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = TextStyleTransferDataset(\n",
        "    df_train,\n",
        "    tokenizer\n",
        ")\n",
        "test_dataset = TextStyleTransferDataset(\n",
        "    df_test,\n",
        "    tokenizer\n",
        ")\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer=tokenizer, model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnk0-fdOD2n3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a34468-5bdc-4b48-f804-68f112484d7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "model_path = \"/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/\"\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=model_path, #The output directory\n",
        "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=20, # number of training epochs\n",
        "    per_device_train_batch_size=8, # batch size for training\n",
        "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
        "    eval_steps=500, # Number of update steps between two evaluations.\n",
        "    save_steps=1000, # after # steps model is saved \n",
        "    warmup_steps=300,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    save_total_limit=3\n",
        "    )\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EkycGNUhEfL2",
        "outputId": "539136b1-372b-44cb-fb72-abbb455de166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 3123\n",
            "  Num Epochs = 20\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 7820\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7820' max='7820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7820/7820 17:02, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.898800</td>\n",
              "      <td>2.036838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.816600</td>\n",
              "      <td>1.806537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.606400</td>\n",
              "      <td>1.730788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.447800</td>\n",
              "      <td>1.543689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>1.335300</td>\n",
              "      <td>1.625414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>1.255100</td>\n",
              "      <td>1.596241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>1.209200</td>\n",
              "      <td>1.565933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>1.145100</td>\n",
              "      <td>1.467975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>1.071400</td>\n",
              "      <td>1.467387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>1.053700</td>\n",
              "      <td>1.558785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>1.012100</td>\n",
              "      <td>1.491096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>0.958900</td>\n",
              "      <td>1.459992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>0.922100</td>\n",
              "      <td>1.570825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>0.915500</td>\n",
              "      <td>1.555882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7500</td>\n",
              "      <td>0.901300</td>\n",
              "      <td>1.409141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-1000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-5000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-5000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-5000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-2000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-6000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-6000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-6000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-3000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-7000\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-7000/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-7000/pytorch_model.bin\n",
            "Deleting older checkpoint [/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/checkpoint-4000] due to args.save_total_limit\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 347\n",
            "  Batch size = 8\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7820, training_loss=1.287011418257223, metrics={'train_runtime': 1026.449, 'train_samples_per_second': 60.851, 'train_steps_per_second': 7.618, 'total_flos': 1161694432604160.0, 'train_loss': 1.287011418257223, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQx0ajdMEkO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "207c3d0f-4949-4200-944b-534db220bc83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/\n",
            "Configuration saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/config.json\n",
            "Model weights saved in /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "trainer.save_model(\"/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdRiKYYWdleF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f151093-0009-4324-b719-060a38476668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/config.json\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading configuration file /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/config.json\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"/content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
            "\n",
            "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at /content/drive2/MyDrive/data/text-transfer-smilegate-bart-eos/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
            "loading configuration file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/54a37e9385f90886428b084042f151c1a699203416d41765d94aac4cddb5fd5c.d098ef3866c1da94bdfaa5c1f24ecb7c5c16b37423b79263fbd3668d2ae61f91\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/f94202e1dad4fcfcb282aff4c6865b6119e03c87c6fa9e5886abe93835c41ecd.dc2013f8bbecd755468e2c44397f53dc624be5451d0190744397caf61a20383f\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/added_tokens.json from cache at /root/.cache/huggingface/transformers/7c75331e2f4b5767db997fbb489f1408eb36a3217beb3057ae8d04bd2b3f97ba.04312f398a3bbda664297588800a86e0fda9d4ef4f0749cd9d96f88043daad39\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/a87d2ed77831bb40ce806a97c04126addf5ecc82b3e23ecf916b2a4acdb9c29a.c23d5e62137984cf842a885705037b25b156747d145406702932d5f5d5e7c88e\n",
            "loading file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/tokenizer_config.json from cache at None\n",
            "loading configuration file https://huggingface.co/gogamza/kobart-base-v2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/54a37e9385f90886428b084042f151c1a699203416d41765d94aac4cddb5fd5c.d098ef3866c1da94bdfaa5c1f24ecb7c5c16b37423b79263fbd3668d2ae61f91\n",
            "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
            "Model config BartConfig {\n",
            "  \"_name_or_path\": \"gogamza/kobart-base-v2\",\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"activation_function\": \"gelu\",\n",
            "  \"add_bias_logits\": false,\n",
            "  \"add_final_layer_norm\": false,\n",
            "  \"architectures\": [\n",
            "    \"BartModel\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"author\": \"Heewon Jeon(madjakarta@gmail.com)\",\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classif_dropout\": 0.1,\n",
            "  \"classifier_dropout\": 0.1,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_attention_heads\": 16,\n",
            "  \"decoder_ffn_dim\": 3072,\n",
            "  \"decoder_layerdrop\": 0.0,\n",
            "  \"decoder_layers\": 6,\n",
            "  \"decoder_start_token_id\": 1,\n",
            "  \"do_blenderbot_90_layernorm\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"encoder_attention_heads\": 16,\n",
            "  \"encoder_ffn_dim\": 3072,\n",
            "  \"encoder_layerdrop\": 0.0,\n",
            "  \"encoder_layers\": 6,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"extra_pos_embeddings\": 2,\n",
            "  \"force_bos_token_to_be_generated\": false,\n",
            "  \"forced_eos_token_id\": 1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEGATIVE\",\n",
            "    \"1\": \"POSITIVE\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"kobart_version\": 2.0,\n",
            "  \"label2id\": {\n",
            "    \"NEGATIVE\": 0,\n",
            "    \"POSITIVE\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"bart\",\n",
            "  \"normalize_before\": false,\n",
            "  \"normalize_embedding\": true,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 3,\n",
            "  \"scale_embedding\": false,\n",
            "  \"static_position_embeddings\": false,\n",
            "  \"tokenizer_class\": \"PreTrainedTokenizerFast\",\n",
            "  \"transformers_version\": \"4.21.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30000\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlg_pipeline = pipeline('text2text-generation',model=model_path, tokenizer=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1wBt0NxdpUQ"
      },
      "outputs": [],
      "source": [
        "def generate_text(pipe, text, target_style, num_return_sequences=5, max_length=512):\n",
        "  target_style_name = style_map[target_style]\n",
        "  text = f\"{target_style_name} 말투로 변환:{text}\"\n",
        "  out = pipe(text, num_return_sequences=num_return_sequences, max_length=max_length)\n",
        "  return [x['generated_text'] for x in out]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCERgrDPdsZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55ab1110-132f-4f65-8b0f-832d4b9f54dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력 문장: \n",
            "  속편이 이정도면,,, 그리 악평이 줄을 이을껀 아닌듯한데,,\n",
            "\n",
            "formal 네, 속편이 이렇게 좋은데, 그렇게 악평을 받을 일은 아닌 것 같아요.\n",
            "informal 그치,편이 이렇게 좋은데, 그렇게 악평을 받을 일은 아닌 것 같아.\n",
            "android 속편. 이정도. 악평. 없음. 추측.\n",
            "azae 아니야편이 이만큼 썩 좋지 않네,,,,,,, 그렇게 악평이 쇄할 상황이 아니였네,\n",
            "chat ᄋᄋ 속편이 이렇게 나오면 그렇게 악평할 이유가 없는 거 같음\n",
            "choding ᄋᄋ 속편이 이만큼 악평이 줄줄?\n",
            "emoticon 이 정도이야...(⊙_⊙;) 그렇게 악평할 일은 아닌 것 같아 (⊙o⊙)\n",
            "enfp 이 정도 완전 완전 대박이야!! ᄏᄏ\n",
            "gentle 제 생각편이 이렇게 좋은데,,,, 그렇게 악평을 들을 이유가 없네요.\n",
            "halbae 그렇다네...내가 보기론...그렇게 악평을 할 이유가 없는 것 같구먼...\n",
            "halmae 이 새끼 놈아 이거 지랄이여\n",
            "joongding ᄋ 속편이 이만큼 나쁘면 악평도 안할듯\n",
            "king 그렇소. 속편이 그리 좋지 않소. 그리 악평을 들을 일은 없는 것 같소.\n",
            "naruto 내 생각엔,, 속편이 이만큼 악평이 많다니깐!\n",
            "seonbi 그렇소! 속편이 이렇게 좋지 않소! 그렇게 악평을 할 이유가 없는 것이오!\n",
            "sosim 아니..편이 이 정도면 그렇게 악평도 할 줄 모르는 것 같아..\n",
            "translator 그것은 사실, 그것은 그다지 나쁜 평가는 아닙니다.\n"
          ]
        }
      ],
      "source": [
        "target_styles = df.columns\n",
        "src_text = '''\n",
        "  속편이 이정도면,,, 그리 악평이 줄을 이을껀 아닌듯한데,,\n",
        "'''\n",
        "\n",
        "print(\"입력 문장:\", src_text)\n",
        "for style in target_styles:\n",
        "  print(style, generate_text(nlg_pipeline, src_text, style, num_return_sequences=1, max_length=512)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rZSFp3uVp6i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc1f037-c3d8-4abb-8941-ebe1f0dd093f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 607 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSWsolTcGV_d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import urllib.request\n",
        "from konlpy.tag import Okt\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U5DdjwgS9Yb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed88bf1-c4fe-4919-9f16-65d31cd54834"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7ff1020e1410>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVLyC0zFTHy5"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_table('ratings_train.txt')\n",
        "test_data = pd.read_table('ratings_test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_yNgb37dAO7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40c5aa2-25f4-4c22-8acb-58334d3b9145"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "test_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lrE90hwl_7Q"
      },
      "outputs": [],
      "source": [
        "train_data, X_test= train_test_split(train_data, test_size=0.9975, shuffle=True, random_state=34)\n",
        "##train_data, X_test= train_test_split(train_data, test_size=0.5, shuffle=True, random_state=34)\n",
        "test_data, Y_test= train_test_split(test_data, test_size=0.8, shuffle=False, random_state=34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqsdufAmrp6P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6308cc9-3d6d-4814-c81c-779e3f2f1021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id                                    9981213\n",
              "document    속편이 이정도면,,, 그리 악평이 줄을 이을껀 아닌듯한데,,\n",
              "label                                       1\n",
              "Name: 12, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "train_data=train_data.reset_index(drop=True)\n",
        "train_data.iloc[12]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWYOIJ4Is9F5"
      },
      "outputs": [],
      "source": [
        "#df_style_transfer = [generate_text(nlg_pipeline, train_data['document'][i], target_styles[2], num_return_sequences=1, max_length=512) for i in range(15)]\n",
        "#df_transfer = [\"\".join(df_style_transfer[i]) for i in range(15)]\n",
        "#df_transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaXkKyX045Hz"
      },
      "outputs": [],
      "source": [
        "#for style in target_styles:\n",
        "#  df_style_transfer = [generate_text(nlg_pipeline, train_data['document'][i], target_styles[style], num_return_sequences=1, max_length=512) for i in range(150)]\n",
        "#  for i in range(150):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-if125bvhS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c020c0-b62e-4669-ae78-6aea1233966c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "375"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohWzrKqa6u4Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86dea394-239c-4ead-e7db-6699de5f4a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['만족감이 거의 없는 영화, 개한테도 큰 한 표를 주고 싶네요.', '추천하고 싶은 영화네요. 모든 분들께 추천해주실 수 있는 영화입니다.', '안녕하세요. 하이틴로맨스입니다. 허리에 손을 얹고 나왔나요?', '드디어 꿈이REAMS COME TRUE을 달성하셨네요. 꿈이 이루어져서 좋나요?', '복서의 아내로, 끝까지 록키를 믿고 따르는 에드리안 같은 사람을 얻어야죠. 주제곡도 최고에요.', '엔딩 씬이 압권입니다.', '안녕하세요,', '구체적으로 말 이런 걸 만듭니까?', '남성과 여인을 둘 다 포용할 수 있는 페미니즘 영화입니다.', '별로 인감이 안 가는 광신도들이네요.', '마리사 토메스의 부활을 꿈꾸고 있습니다. 조금만 세련되게 만들었으면 좋겠어요.', '저도 예중에서 예고를 준비하는 병창입니다. 예고에 합격하면 두레소리에 지원해보고 싶어요.', '속편이 이만큼 썩었으면, 그렇게 악평을 할 이유가 없는 것 같아요.', '너무 한네요. 아무리 인심을 좋게 보려고 해도 오글거려서 20분을 못 넘길 것 같아요. 어릴 때 봤던 이필립 에로 영화가 훨씬 나을 것 같아요.', '누가 봐도해도 하위권입니다.', '가장 나쁜 영화, 도중에 보다가, 오직 음악만 들을 수 있어서 보는게 후회되네요.', '런닝 시간을 20분 정도 더 늘렸으면 하는 아쉬움도 있지만, 애니를 좋아하는 사람이라면 꼭 봐야 할 영화입니다.', '모성을 처음부터 키우기보다, 모성을 찾아가는 과정이 참신했어요.', '제가 본 영화 자체가 뜻밖의 여정이네요. 다섯 군데에 가서야 볼 수 있을 것 같네요. 진짜 최고 반지의 제왕 시리즈는 안 봤지만, 최고령 반지의 제왕 시리즈는 봤습니다.', '평점이 낮아서 저도 1점 얻었습니다.', '그건 정말 좋은 것 같습니다. 안 봤으면 꼭 보길 바래요.', '정말 20년3년 인생에서 가장 불운한 영화입니다. 마치 영화에 대한 이해가 없는 것처럼 보여요.', '네, 이쁜 흙을 먹습니다.', '원작 게임 자체가 그리 깊이 있는 스토리가 아니여서 영화에서 이야기할 수 있는 내용이 많지 않은 건 어쩔 수 없는 일이에요. 이 영화는 신선함은 조금 떨어지지만 최소한 원작을 망치지는 않았으며 내용이 엉성하지도 않았습니다.', '1위는 아니니 평점 조정을 하러 가요.', '네,베르마 선생님도 울고 저도 울었습니다.', '좋은 아이디어 같아요.', '맞는 도둑들이 많아서 재밌었어요. 앞편에서 보면 도둑2명은 몸개그보다 약했지만.', '정말 멋 군요. ', '아니요, 안나왔으면 좋겠네요.', '굉장히 재미미 없는 이야기지만, 공룡이 들어와서 장난을 친다는 설정은 재밌을 것 같습니다.', '아직까지도에 선한 주제가의 노래입니다.', '대역도, 영화예고편 자체가 낚시 같다면, 차라리 케이블에서 해주는 19금 단편 영화를 보는게 낫지 않을까요?', '휴먼 때문에 봤는데 지루하네요.보다 꺼버린 영화가 처음이였어요.', '정말 별였지만, 평소에 아주 지루하게 죽어나가는 줄 알았어요.', '제가 이 이빨을 왜 봤는지 모르겠어요. 하지만 검색을 해보고 싶습니다. 너무 짜증이 나요.', '시간을 때우기에 좋습니다.', '뮤지컬을외한인 제가 볼 수 있는 건 정말 신선한 자극입니다. 그냥 보고만 있으세요. 그리고 나서 흥분을 하세요.', '4번정도 봤어요. 그래서 알았습니다.', '주로 실화를 그렸지만, 내용은 사실적이고도 아버지님의 눈물 연기가 볼만 하네요.', '굉장히 무서 무서워서 볼륨을 작게 해서 본 영화입니다. 엑스맨 시리즈의 로그 역에 배우 안나 파킨이 나오는데 그 와중에도 눈이 갔어요.', '시나리오는 별명이지만, 배우들이 만든 영화입니다.', '이 영화는 다운 받아서 보세요.', '전 제습니다. 제시카를 정말 사랑합니다.', '평점 7.3가 딱인 비디오물인데, 너무 높아서 1점입니다.', '로또하게 만드는 영화, 제 인생에서 가장 후회하는 영화는 아직까지도 남아있습니다.', '아무도 할 꿈을 꿀 수 없는 것 같아요.', '별로 기대 안하고 봤는데 정말 최고네요. 이런 영화가 자주 나왔으면 좋겠어요.', '언제 봐도 봐도 참 매력있는 영화입니다. 영화가 원작을 잘 살려서 좋은 영화로 만들어주셨어요.', '감독의 말이 같은데, 제대로 된 감독 만들려면 제대로 만들어둬야죠.', '오버연기를 기대하고 있습니다.', '복수를할 겁니다.', '좋은 영화 같아요. 꼭 봐야할 영화에요.', '우리는 이 영화를 기억해야 합니다.', '평소에 어땠나요? 약간의 유치한 부분은 있었어도 몇번을 봐도 명작이네요.', '안녕하세요.', '재밌지 너무 재미가 없네요.', '관중들의만 믿고 가겠습니다.', '전 두준오빠가 좋아서 봤는데 이제는 정말 좋아졌어요.', '애절한 사랑에서 섬뜩한 사랑으로, 15년만에 다시 만난 황장군이라는 단어와 함께 글을 써요.', '재미있네요.', '안녕하세요.', '시간이 남아 사람만 인내심을 갖고 보길 바래요. 감독의 역량이 부족합니다.', '아마 서영희는 정말 미친년일지도 몰라요. 그만큼의 역활 그 이상을 보여준 명연기였죠.', '1인칭 시점의 화소는 참신하지만, 왠지 답답한 느낌을 주네요.', '화면은 참 예뻐요. 그 다음으로는 뭘까요?', '완전히 재밌습니다. 이제야 보니, 공유 액션연기가 시작됐네요.', '엄청 재미있잼네요. 처음 보는데 엄청 긴장했어요. 잔인하고 무서운 신이여서 깜짝 놀랐어요.', '이전에 없었던 아동성추행범 코드는 왜 넣었나요? 프랜시스 셤도 미스캐스팅에 본토에서 너무 쉽게 망한 이유가 있는 것 같아요.', '액션신은 볼만 하네요. 하지만 한국어를 알아듣는 한국인이 보면 질릴 정도로,,,, 북한 테러리스트들이 부르는 한국어도 나오고요.', '꽤 기대 기대했는데, 산만함 그 자체로 볼만 한 영화는 아니였어요.', '이 정도면 충분합니다. 10점 만점에 10점입니다.', '코믹과 드마라가 결합한 재밌는 영화입니다.', '둘 다 가질 수 없는 사랑, 끝나고 너무 아쉬웠어요. 마고의 섬세하고 섬세한 감정연기는 못 잊을 정도로 아쉬웠어요.', '보는 내내 얼마나 가슴 아팠던지 결말이 뻔할 수 밖에 없잖아요.', '끝까지 보기하기 힘든 영화 배우들은 연기가 떨어져서 집중이 안되요. 책을 읽었어요.', '곧 개봉 날이에요. 왜 흥행 대재앙 영화인지 알겠습니다.', '네, 몇 명 연기가 어색했지만, 보다보니 재밌게 봤어요.', '영화 자체가 그렇게 길게 끌다가 끝나고 나면 뭐하는 기분이었지만, 피아노 연주는 멋있었어요.', '안녕하세요.', '재밌어요.요.', '하이재킹을 소재로 한 영화 중 최고라고 자부할 수 있어요.', '도라에몽이랑 같이 요미하다고요?', '전혀 웃기지도 않고, 억지스러운 쇼를 보는 건 요즘 세상에 평범한 일입니다.', '다음 주 더 바빠지지는 않았나요?', '사회 부조리에 미친 사람들이 돌아가지고 상어가 나오고 하드코어 쇼를 한다는 것부터가 개미범들이 귀여워서 조금 재밌었어요. 가장 디테일한 영상이 제트스키에요. 앞에서 상어가 머리를 무는 장면 정도인가요? 집에서 보기에도 시간 아까워서 걍 TV를 보는 것 뿐입니다.', '처음에는 스펙타클하지만, 결국에는 빛 좋은 개로 돌아오는 셈이 되는 것 같아요.', '굉장히 깊이롭고 재미있는 영화입니다.', '액션은 너무 지루해요.', '네,,,, 윤두준 선수도 화이팅!', '한효주님 동생 사건을 넘어서서 연기가 정말 겉도는 것 같아요. 역할에 대한 이해가 전혀 없어서 아쉽고, 최하점인 것 같아요.', '안녕하세요. 재미있게 일하시길 바래요.', '아니요,왜 덧씌우세요? 절대 안 봐요. 올해 최악영화 1순위입니다.', '감사합니다.니다, 저는 강호동이 나가고 나서 재미있게 지내고 있습니다.', '뭔 내용인지 모르겠네요. 기무라타쿠야가 불사신인가요?', '아마 더구가 더 가족적이고 백바가 더 낫다고 생각했겠네요. 이 정도는 많이 주셔야 7점짜리일거에요.', '케빈 형제는 작품을 고를 때 안목이 없으신 것 같아요. 그래도 다행이네요.', '긴장을하면서 집중해서 꽤 재미있게 봤어요.', '정말 화습니다. 일단 캐릭터들간의 밸런스가 영화에서는 너무 어긋나요. 그리드 후면 곤 키르아는 적어도 거미하고 동급일텐데, 그러지 못하고 액션신은 상영관이 아니라 하버에서 보는 것이나 마찬가지입니다.', '이건 뭐, 초등학생 소설도 아니고 세상 참 편하게 사는 두뇌들입니다. 특히 빨갱이를 감싸주면서 개수작을 논리적으로 피우는 우리나라 대통령이라니.', '몸만 다른 존시가 나올 줄 알았어요.', '아깝, 220억입니다.', '저는 아름다 아름다워요.', '살인 게임 게임은 참 유치한 장르 같아요.', '하지만 우먼 팬들은 그냥 웃어주는 것 뿐입니다.', '그렇게 낮은 점수평가는 아니지만, 최소 7점은 넘어야하지 않을까요?', '개재미가 없나요?', '무섭지도 않고, 재미도 없습니다.', '인물들 관계가 약간 복잡할 수도 있지만, 대사들에 따르면 재미있는 것 같아요.', '우베볼인 것을 생각하면 정말 훌륭합니다. 그리고 우베볼 영화가 아니더라도 괜찮은 영화에요.', '네, 당연한 말씀입니다.', '맞아요, 그런 또 하나 버전의 버전일 뿐입니다.', '5탄을 보고나니 4탄이 얼마나 선전했는지 알 수 있겠네요. 1,3편 정도만 봐도 알 수 있을 것 같아요.', '시청하지 못해서 내용을 알 수 없었다고 해요.', '엄청 재밌습니다. 특히 류현경 배우가 예쁘네요.', '정말 기가 막히는 쇼네요.', '평론가들의 평점이 어이가 없어서 로그인하게 만듭니다. 이게 6점인가요? 극장에서 본 내 인생에서 가장 아까운 영화입니다.', '쓰레기입니다.세요?', '김민희씨는 이쁘고 매력있네요.', '비교적 쉬운 역사 공부를 하고 있습니다.', '맥도페인 게임을 안해봐서 게임은 잘 모르겠지만, 영화는 그닥 나쁘지 않았어요.', '엄청난 쓰레 쓰레기가 세상에 나왔네요. 무슨 말이 더 필요하나요?', '너무 오글거려요. 정말 시간이 아까워서 5분만 보고 꺼버린 영화에요.', '확실히 이해지는 못했지만, 명작은 분명 있습니다.', '참신하고 스토리 좋지만, 점수를 줄 수는 없는 영화에요.', '90년 한국영화에도 요런 스릴러가 있었네요.', '줄거리만 길게 줄여서 긴장하는 것 같아요.', '사랑해 해본 사람이 느낄 수 있게 아주 잘 만듭니다. 모두들 최고라고 생각할거에요.', '저도 나이가 나이를 먹어보니 굉장히 훌륭한 동창회였네요. 또 볼 수 있을까요?', '하이,우먼.', '더럽고 끈적하고 짜증이 나지만 너무 슬프네요.', '명작입니다.', '그냥,애들은 징그러워요. 복장이고 성생활이니까요.', '정말 멋있네요. 최고입니다.', '명불허전 서극의 숨은 명작입니다.', '아,, 치바 유다이에 정말 귀엽게 나왔네요. 100점 만점에 감사합니다.', '저만 재밌었던 것 같아요.', '의외로 볼만합니다. 충분히 봐줄 수 있을거에요.', '꿈을 먹고 삽시다. 영화는 제 영화입니다.', '굿모스를 뽑습니다.', '춤추는 펭귄이라는 주제만이 아니였어요.', '저는 추태문화 체험하는 과정이 너무 지루합니다.', '눈 썩 멎는 것을 보고 안구를 포기하고 싶네요.', '전반부에서 쏟아낸 재치와 달짝지근한 엔딩으로 작위성을 조금 흐리게 했어요.', '잠시만 보시면 재밌을 것 같네요.', '늦었지만 봐도 두 배우의 연기력과 진정성이 느껴지는 영화네요.', '굉장히 의미 깊습니다. 생각이 있으신 분이라면 알겟네요.', '너무 무무서워요.', '정말 재밌게 본 작품인데, 속았구나요.', '계속 웃었던 영화입니다. 굉장히 재미있었어요. 말 많고 화려한 코미디 영화보다 더 재미있었어요.', '두 손이이 묶인 상태에서도 레슬링 선수와 싸우는게 정말 힘들었어요. 두 손을 묶고 뛰기란 정말 힘든 것 같아요.', '정말 쓰레기 같은 영화를 다 봤네요. 왜 빵점이 없나요?', '드라마를으로 로또를 받았어요.', '재밌어요, 언제 끝나나요?', '평점이 9점대가 아니에요.', '보고 또 볼만 한 드라마입니다.', '아마도 역 본드일겁니다.', '그냥 쓰레기 영화 자체가 너무 재미없어보는 내내 하품이 나왔던 영화여서 재미도 없었어요.', '엄청 재미 재미없네요. 한숨이 나왔어요.', '굉장히 재밌게 봤어요. 예전에 봤던 영화인데도 재밌었어요.', '처음 접하시는 분들은 영원히 다시 접하지 않을 것 같아요.', '브루스스의 윌리스를 보면 왠지 요즘 떡밥이 생각나네요. 브루스에 나왔을 때 대작이라고 생각되지 않아서 평점도 안 받았어요.', '굉장히 험 상황이네요. 힘들어요.', '어째서 이렇게 평점이 안 좋나요?', '눈물도 있고 웃음도 있고 괜찮았던 영화였네요.', '시간가는 줄 모르고 봤어요. 농장이 아닌, 공장식 축산업이 얼마나 우리들에게 편리한지 그 어떤 것에도 설명하지 않고, 식문화와는 절대 무관한 우리 인간들이 꼭 알아야할 부분을 잘 말해주는 영화였어요.', '무슨 생각상으로 만든건가요?', '분명 감적인 면도 있지만, 프로그램 자체가 참신한 것 같아요.', '그 동안에 빠져서 늘 그 시간이 기다려졌는데, 이제는 너무 아쉽네요. 그 시대를 정치사로 회귀해 볼 수 있었던 것도 재미중 하나입니다.', '긴장을감을 많이 했는데 평점이 생각보다 낮네요.', '전혀 다른도 안 맞고, 논리도 없고, 대신 허영심에 가득 찬 히어로 영화입니다.', '예술가라면 누구나 가능하겠네요.', '네이버이버 영화 소개합니다. 비극과 코미디, 스릴러와 로맨스를 아우르는,,,,,,,,,,,,,,,,,,,,,,,,,,, 대단하네요. 제 간만에 이렇게 지루하고 축축해지는 영화를 처음 봤어요.', '좋은 영화지만, 우연적인 상황이 너무 많아요.', '분명 복수심에 불타는 건 인정하지만, 범인의 수준에서는 상상도 할 수 없는 일이잖아요. 무협지도 아니고, 평범한 학생이 갑자기 007급 능력자가 되나요?', '보긴하지만 그렇게 강렬한 인상을 남겨서 기억에 남는 영화는 아니었던 것 같아요.', '해피엔딩이지만 마음 한편으로는 아프네요.', '별로 안 없습니다.', '재밌네요.', '어둡서 그런가요?', '원작을 나름 재미있게 구성한 것 같네요. 엄청 재밌게 봤어요.', '잔잔하고 여운있는 영화였어요. 커피를 마시고 싶네요.', '저도 신기가 납니다.', '선우일란의 육덕을 찬양하세요!', '기대해 기대했는데, 정말 실망했어요. 기자들의 말처럼 시작은 정말 강렬했어요. 하지만 나치를 언급할만큼 거대한 디 비전이 보이지 않았어요. 이 영화보다는 5:5의 전쟁을 보는게 나을 것 같습니다.', '제목대로 기묘한 이야기에 대한 호불호가 분명히 갈리는 영화입니다. 개인적으로 추천드립니다.', '또 라 세리입니다. 누가 7점 8점이래요, 이 영화는 10점이에요.', '추억을 많이 쌓으시길 바랍니다.', '정말 기대 기대되네요.', '어린 애들의 순수한 사랑을 그린 영화입니다.', '귀여운 고양라미 노래를 부르던 한 청년의 노래가 참 슬펐던 것 같아요.', '멋있는 배우들의 연기가 정말 아름다운 것 같아요.', '볼레로가 정말 좋았어요.', '굿모굿, 굿 굿 굿', '완전히 재밌었어요.', '네, 지금 보고 있는 중입니다. 진심 지루하고 군더더기가 많은 영화입니다. 더빙인데도 어색하고 톤이 너무 지루합니다.', '그냥,습니다.', '네, 하지만 두가풍으로 2점씩 주려고 합니다.', '예쁜 사랑 볼 수 있어서 좋았습니다.', '미생 성대리가 쥔 공입니다.', 'BBC는 실망하지 않았습니다.', '1점 하나도 아깝지 않나요?', '대단하세요네요. 지상에 눈이 멀어서 인류를 배반하는 것이 아닌가요?', '아무 생각 없이 볼 수 있는 B급 괴수류 블랙코메디아입니다.', '클라리입니다. 이 영화를 보고 난 후로 암이 사라졌어요.', '일단 어실 수 있으면, 최강의 반전이 당신에게 기대되네요.', '최고 영화 영화를 잊고 있었습니다. 어느 순간 다시 생각나네요.', '네, 너무 오래 걸렸어요.', '분명 마지막액션만 아니면 볼 수 있을거에요.', '그건 다저럭 괜찮습니다.', '그렇게 재미 재미있게 읽을 수 있는 책이 안타깝네요.', '제 추억과 주제곡 때문에 10점 만점에 10점입니다.', '원작은 어디에서 온 작품인가요?', '최근에 본 영화 중에서 가장 후회하는 영화입니다. 시간이 아깝다고 느낀 건 처음이네요.', '마지막까지 개그하는 주성치입니다. 티격태격하는 것이 너무 재밌어요.', '그런가요?', '다 필요 없고, 여주인공이 너무 예뻐서 넋 놓고 봤어요.', '평소에 보고 봤는데 훨씬 좋은 영화였어요.', '이해는 하지만, 감당이 안되네요. 대신, 옥희의 영화를 보면서 기분 전환을 해야겠어요.', '그러면 남는건, 공화당 찍으세요, 이민자를 조심하시길 바랍니다.', '굉장히 무모해 보이네요. 제작진도, 출연진도, 모두 동의합니다.', '안녕하세요. 저는 하우스 오브 레비입니다.', '네,,,', '동전요, 그리고 남자분은 능력이 있으십니까?', '재밌을 줄 알았는데 너무 아쉽네요.', '너무 왜곡되어서 망한 영화, 역할은 정말 맘에 안들지만 원래 좋아했던 여주인공 때문에 끝까지 보는 걸 추천드립니다.', '하나님의 사랑 다시 한번 확인할 수 있는 시간이었습니다.', '어째서 이렇게 평점이 높은 건가요?', '인류의 욕정은 늙어서 죽어나갈때까지 사라지지 않는가요.', '쓰레기 같은 영화네요. 진짜 영화를 보다가 후회했어요.', '어째서 그런가요? 요즘 사람들은 관심이 없나요? 동화같은 이야기도 있지만 꽤 볼만하다고 생각합니다.', '이 영화는 액션물도, 스릴러도, SF도, 심지어 드라마 장르도 아닌, 그저 드라마 장르입니다. 그렇다고 최루성 멜로도 심금을 울리는 감동적인 내용이 아닙니다. 그냥 의사의 처방이 있어야 살 수 있는 수면제를 대신해서 지친 몸을 쉽게 잠재워주는 수면 영화에요.', '마치 명절에 하는 단막극 같네요. 굉장히 편하고 재밌는 영화네요.', '볼만 있겠지만, 평점이 너무 높아요.', '제가 처음 왔던 그때를 간직할게요.', '슬픈 곳이 어딜까 라는 생각을 했는데, 저도 모르게 눈물이 흘러나와요. 억지로 눈물을 이끌어내는 것이 아니라 정말 진지하게 눈물을 흘리게 만드는 영화에요.', '그걸 보고 수2를 풀고 영어단어를200개정도 외워주세요. 점수를 줄 수 없어서 1점만 줄게요.', '10점 만점에 10점입니다.', '마음이 아프 아프네요. 어머니한테 더 잘해야죠.', '어떤 문제가요?', '재밌네요. 10점 준 것 중에 한국영화는 9~10점 주는데 미국은 10점 주려고 합니다.', '만화 코스프레를 넘어서서 연기, 액션이 최상의 컨텐츠입니다.', '아, 따듯하네요. 전 천국의 아이들 못 보시는 분은 꼭 보시는걸 추천드립니다. 같은 감독님이시네요.', '영화는 명작인데, 여기서 나온 것이 납치를 한 사람을 돕는 현상으로 해석하나요?', '네, 영화 제목이 기억에 안나는 영화입니다.', '처음으로 아가들이 집중해서 봤네요.', '네, 함께 1981년의 몬트리올에서 퀸과 프레디 머큐리를 만나는 시간 여행을 떠나요.', '참된 교훈을 준 영화에요.', '평점은 낮지만 후세에게 기억에 남는 매니아적인 영화입니다. 감독의 천재성이 대단합니다.', '주제도 식상할 뿐더러, 대안이 없어요.', '그걸 본 사람도 대단하시네요.', '보기 전 좋은 선택이네요. 끝까지 보고 싶습니다.', '죽으냐 살았냐가 문제였네요.', '네,캐스팅입니다. 캐릭터들을 고대로 따오느라 2주가량 걸려서 2점입니다.', '괜찮은 보이던데, 달리다가 쳤을 때 가장 놀랐던 사람이 누군가요?', '개미 사회를 주제로 한 영화라 참신했어요.', '영화사에서 최고의 엔딩 씬이 아닐까요? 웃기면서 마지막에 울리는 감동의 순간입니다.', '고등학교 졸업 졸업생인 저로써는 카이스트에서 우등생으로 졸업한 것을 자랑스러워합니다.', '네,캐스팅에 기대해 봤는데, 너무 불친절하고 사람들이 원하지 않을 것 같아요. 선문답 같은 영화인데도 길이까지 이렇게 길다니요.', '말이 필요 필요 없습니다.', '이게 실화라면 드래곤볼도 실화입니다.', '재밌네요, 어째서 만드신건가요?', '말이 필요나요? 정말 예전에 봤는데도 뇌리에 선명한 영상이네요.', '네, 그리고 감독의 평점이 생각보다 낮아서 주는 것이 아니라, 8~9점정도로 수작이지만 아름다운 영상으로 가득차서 보는 즐거웠어요. 사극이라서 더욱 좋았고, 원작에 대한 비교는 안했지만, 감독의 다세포였기에 초창기부터 좋았습니다. 하지만 감독의 역할이 다세포였기에, 전반부는 좋았습니다.', '네,,, 차라리 여자가슴 사진을 한장 보는게 낫다고 추천해드렸어요. 이런 것을 평점으로 매기는게 어땠나요?', '재밌어요, 재밌어요, 재밋어요, 재밌어요.', '안녕하세요, ᄒᄒ', '가장 좋아하는 영화입니다.', '좋아하시 하지만 왜 그렇게 생각하시는건가요?', '멀리 갈기를 기대하고 있나요?', '굉장히 짜스러운 구타유발 인물들이 많이 등장합니다.', '달곰하네요.', '네, 너무 좋아해요. 장국영을 보고 싶어요.', '실망하세요요, 완죤을 좋아하던 프로였습니다. 이번 시즌은 정말 실망했어요.', '레전드는 정말 대단하시네요.', '재미만 따지면 안될 영화네요.', '오랜만에 만난 좋은 영화입니다.', '요리사가 분홍색 머리를 매만지는 건 아니시네요.', '오늘 봤봤는데 옛날 영화치고는 볼만 했네요.', '이건 마치 마라톤 경기를 하는 영화랑 비슷한 수준의 영화입니다.', '다른 성룡 영화에 비하면 조금 덜하지만 그래도 재밌어요.', '남편이 울 흘릴 때도, 마지막 어머니의 마지막 모습도 눈시울을 적셨을거에요.', '아토피와 치질로 고생하는 태헌이의 건강과 자유를 빌어줘서 감사합니다.', '아이고 그건 좋은 아이디어네요.', '장르를 속여서 1점 영화는 분명 코미디입니다.', '두 배우의 대결을 보는 것 보다도 너무 긴장감이 높아요.', '개 양아치들의 일상을 그린 레알 쓰레기 영화입니다.', '일본 영화는 영화부터 상영하는 것이 민폐입니다.', '몰리는 왜 죽으시는 건가요?', '액션장면은 그나마 볼만 한 것 같아요.', '그런 의들은 안 봐도 뻔합니다.', '어떤 점이요?', '가장 현실적인 웃음과 감동 문제를 풀어나가는 방법을 재밌게 봤어요.', '네, 외국 아이들이 제 눈깔을 이상한 눈깔로 보게 만들어준 영화입니다.', '이게 영화인가요? 요즘 같은 시대에 돈을 얼마나 많이 써버렸는지 영화를 보다가 들으면서 짜증이 나는 건 처음입니다. 펜싱은 손으로 하는 운동인데, 이 영화를 배우면서 처음 느끼는 것 같아요.', '네, 네 명의 삶을 보여줬을 뿐이지, 그저 그런 밋밋해요.', '재밌네요, 감사합니다.', '너무 재밌습니다. 마치 황진이 타는 것 같아요.', '잘 모르겠습니다. 처음에는 너무 불쌍한 것 같았지만, 결국에는 인간들이랑 생활을 그리워한다는 느낌을 지울 수 없었어요. 인간들이 님을 이용했던 건 맞지만 과연 그것이 님께선 불행이였을까요?', '너무 길게서 7번이나 걸었네요. 마지막 10분의 강렬한 인상을 남겨서인지, 주인공들이 미스캐스팅과 잘 어울리지도, 재미도 없습니다.', '여태까지 본 외국 영화 중에서 가장 웃긴 영화입니다.', '표지만 멋있네요. 그저 공포영화를 만들고 싶은 3류 영화제의 표본입니다.', '야구는랑은 일종의 커플이네요.', '예고편에 속았어요.', '정말 꿀 개꿀잼 정자가 너무 예쁘네요.', '잊고 있었는데 다시 보니 너무 반가웠어요. 이제는 꼭 다시 보고 싶어서 주문했습니다.', '보는 내내 내내 불편한 영화네요.', '네, 하워드는 너무 졸려서 못 읽었어요.', '소피마르소라는 캐릭터는 아름다워 보이지만, 끝까지 가면 지루하고 이해하기가 힘든 작품입니다.', '아,본디 기억이 잘 안나지만, 약간은 SF와 비슷한 상황입니다.', '저는 재밌었는데 평점이 너무 낮네요. 명작까지는 아니더라도 이정도면 볼만할 것 같아요.', '이 영화를 개봉한다는게 더 공포스럽네요.', '액션도 내용도, 내용도, 시간도 아까워요.', '개인적인 생각지만, 요즘의 몇몇 자극적이고 공상적인 한국 영화보다 이 영화처럼 서정적이고 현실적인 내용을 따뜻하게 담은 영화가 정말 좋습니다. 영화 마지막에 재미있는 이야기가 이어져지나 싶었는데 영화가 끝나는 것이 조금 아쉬웠을 뿐입니다.', '그냥,해상에서는 괜찮아요.', '대단하세요요. 시즌3니까 평점 3점을 줘도 너무 평점처럼 매겨지지 않습니까. 선생님하고 멘티의 관계가 너무 끈적끈적하잖아요.', '파파에서 걸을 때 마다 총으로 쏴 죽이고 싶었어요.', '네이버 평점은 정말 기대하기 힘들 것 같습니다. 정말 재밌게 봤어요.', '영화 요소요소에 배치가되어 있는 압도적인 영상미와 빼놓을 수 없는 3일간의 이야기입니다.', '너무 재밌네요. 열심히 본방사수할게요. 언젠가부터 파이팅이 시작될거에요.', '최고의 힐링 영화입니다. 귀농을 하고 싶네요.', '굉장히 재미있쾌한 쇼입니다. 하지만 스토리도 부족하고 너무 다이내믹해서 인기가 없습니다.', '감동을 주는 좋은 영화네요. 예술하는 사람들은 여러가지 이유로 유혹을 받는데, 마음을 알아주는 사람을 만났으니 기쁜 것 같아요. 재밌게 봤습니다. 남 배우님 차분한 목소리를 좋아하시네요.', '안녕하세요. 저는 오마이 갓입니다.', '이정재는도 매력이 넘치는 킹왕짱입니다. 이정재의 연기가 정말 멋있어요.', '돈을 주고 이런 걸 만들고 싶나요? 영화제작자분들은 모니터를 안하시나요?', '재밌어요.요.', '재밌는요. 이런 계열 드라마 중에서는 최고입니다.', '시즌2에서 깔끔하게 끝났으면 더 명작으로 남았을텐데 자꾸 억지로 전개를 시작하는 것 같아요.', '안녕하세요, BBQ BBQ는 생각 없이 낄낄대면서 보기 딱 좋은 영화입니다. 그리고 제시카 알바, 스티븐 시걸도 나왔어요.', '잔잔한 감동의 영화를 보고 나서, 오늘 장진영 감독의 영화를 보고 싶네요.', '이정재의 성룡이랑 같이 저번주에 왔었는데, 왜 그렇게 런닝 시간을 많이 잡아서 배우들의 고충을 더 크게 하는건가요?', '잔잔한 감동, 빵빵 터지는 코미디까지 있는 정말 최고의 영화입니다. 쓸데없이 스케일만 큰 블록버스터보다 2만배는 더 재밌어요.', '소홀히 했던 다섯가지 시선들을 볼 수 있었습니다.', '다리가 붕괴장면에서는 CG는 그림판에 검은색을 선택하고 크랙을 통해 오른쪽으로의 탈출을 시도했습니다. 아파트에서 내려온 사람이 아파트에서 내려온 사람을 가리는 역할을 한 셈이 됐지요.', '주인공을 처음 보고 처음에는 피카레스크라도 하는 줄 알았는데, 아니였어요. 요즘 사극은 다 리지트를 풀고 나서는 재미가 없네요.', '억지 부리고 착하지 못한 진주가 제게 복수를 하는 것을 보여드릴게요.', '대학교때 때 이 영화를 7번 봤는데, 질리지 않는 만점 영화였어요.', '영화에 돈을 벌기 위한 영화가 아니였나요? 예술 영화에 가까운 영화에요. 평점을 주세요.', '그건 좋은 영화에요.', '정말 따뜻하고 괜찮은 영화네요.', '네, 재밌네요.', '금요일이 기다려집니다. 최고입니다.', '애들 데리고 봤는데 다들 반응이 좋네요. 애들 데리고 보러 가보시길 바래요.', '눈이 즐거 즐거웠어요.', '토사물 똥쓰레기를 처리하는 시간이 너무 아까워서 미치겠어요.', '서태지씨가 방가워요. 어제 티비를 잘 봐서 종종 나오세요.', '백형 감독님. 차기작을 하셔야죠.', '너무 좋은 영화지만, 에너지를 너무나 소모하게 하는 영화입니다. 이 영화를 만난 것에 감사드립니다.', '딱히 말씀드리면, 굉장히 혼란스러운 상황입니다. 시작부터 배우들의 연기에 실망하고, 어떤 의도를 가지고도 작품을 할 줄 모르는 감독의 연출력에 실망하고, 특이한 형식을 살리기 위한 감독의 노력에 실망하고, 심지어 음악까지 실망합니다. 이 영화 끝까지 본 저 개인적으로는 실망합니다.', '다른 좀비영환에 무조건적인 백신 찾기, 분노바이러스가 이렇게 안되어지게 해줘서 좋았어요.', '아, 드라마는 정말 말이 안되고, 비현실적입니다. 그냥, 상식에 비추어 봐도 아닌 것 같지만,, 더 이상 볼 수 없겠어요.', '몰입 하나만으로도 이 영화는 충분했어요.', '이건 오직 감독님 작품입니다.', '굿 굿입니다. 긴장감 넘치는 영화입니다.', '지원언니 미자를 연기해줘서 감사합니다. 사랑합니다.', '아직 세은은 따듯하다는 것을 느끼게 해준 훌륭한 영화였습니다. 소아암에 걸린 아이가 희망을 잃지 않고 항상 웃는 모습에 많은 것을 배웠습니다. 추천하고 싶습니다.', '이야기는 뻔하지만, 마치 홍콩 느와르를 보는 기분처럼 시원해지는 것 같아요.', '10점 만점에 10점 정도지만, 평점 10점 만점에 10점 만점입니다. 감독의 평점인 10점짜리 공포영화입니다. 전 반전도 있고 인간의 심리를 리얼하게 보여주는 공포영화입니다. 믿으시나요? 제가 본 공포영화 중 가장 무서운 영화입니다. 공포영화인데도 공포영화로도 유명합니다. 공포영화로도 유명한데, 공포보단 심리 스릴러 장르의 공포영화를 선호합니다.', '유명한 배우가 나와도 영화는 못 따라줍니다.', 'sf는 특히나 주제가 잘 안 되는 설정은 오히려 암적요인이에요.', '재밌을 보이네요. ', '좋은 소 살린 OO 감독입니다. 조금만 잘 했어도 대단한 영화가 되었을텐데 아쉬워요.', '비교적 보기 보기 좋은 것 같아요. 마치 동화같은 이야기입니다.', '정말 슬픈 영화 중 하나에요. 어쩌면 인생에서 가장 선호하는 사람은 박민수 매니저일지도 모르겠네요. 가장 하고 싶은 일이 철 없이 사는 것 일수도 있다는 생각에 문득 슬퍼졌어요.', '스타크래프트 외전인가요? 오버로스가 비행기를 공격해버렸어요. 상상쟁이 브루스 워스워스는 재수없어요.', '톰크루즈의 그 당시 진짜 이 영화는 인기가 대단했었습니다.', '영화도 재미있지만 ost ost는 정말 예술입니다.', '콩이이요, 콩신입니다.', '보는 순간마다 푹 빠져서 재밌게 봤습니다. 감사합니다. 영화를 다 보고 철수가 불쌍하다는 생각이 들었지만 철수가 행복해 보이니 그걸로 된거겠죠.', '벌써 몽정한 아이들에게 좋은 영화에요.', '1편을 보고 왔는데 너무 놀랐어요.', '어릴 때 정말 재밌게 봤던 시리즈입니다. 상영시간이 1시간 정도밖에 안 됐어요.', '분명 유치 유치할 줄 알았는데, 나름의 어린이용 영화로 그 어설픈 분위기를 완전히 바꿔버렸어요.', '이렇게 재미 재미있을 줄 몰랐네요. 너무 실망했어요.']\n",
            "          id                                           document  label\n",
            "0     280788                     만족감이 거의 없는 영화, 개에게 큰 한표를 주고 싶다      0\n",
            "1    5086827                               적극추천하고픈 영화입니다 모든분들에게      1\n",
            "2    5289443                 성인버전 느끼 에로 하이틴로맨스물. 허리에손은 뭐하러 나왔나?      0\n",
            "3    7252623                 아주 DREAMS COME TRUE네. 꿈이 이루어져서 좋냐.      0\n",
            "4    9978482  복서의 아내로서 끝까지 록키를 믿고 따르는 에드리안 같은 아내를 얻어야되 정말 최고...      1\n",
            "..       ...                                                ...    ...\n",
            "745  1757700                              벌써 몽정한 아이들에게 좋은 영화에요.      1\n",
            "746  9712565                                1편을 보고 왔는데 너무 놀랐어요.      0\n",
            "747  3399950       어릴 때 정말 재밌게 봤던 시리즈입니다. 상영시간이 1시간 정도밖에 안 됐어요.      1\n",
            "748  5749636  분명 유치 유치할 줄 알았는데, 나름의 어린이용 영화로 그 어설픈 분위기를 완전히 ...      1\n",
            "749  1967825                      이렇게 재미 재미있을 줄 몰랐네요. 너무 실망했어요.      0\n",
            "\n",
            "[750 rows x 3 columns]\n",
            "['만족감. 적음. 영화. 개. 티켓. 지급. 희망.', '추천. 영화. 선호. 희망. 모든. 휴먼들.', '안드로이드.. 성장기. 하이틴로맨스. 착용. 허리. 손. 무엇. 했는가.', '긍정. DREAMS. COME TRUE. 꿈. 이루어짐. 희망. 있는가.', '복서. 동반. 끝까지. 록키. 믿고. 따르다. 에드리안. 동반. 최고. 주제곡.', '엔딩. 씬. 제일. 선호.', '안드로이드.over.', '의미.. 무엇인가. 이런. 만들기. 어려움. 별점. 없음. 신주아. 7년. 수행.', '남성과. 여지. 둘 다. 포용. 가능한. 페미니즘. 영화.', '표정. 광신도. 표정. 없음.', '마리사 토메이. 복귀. 희망. 약간. 세련됨.', '안드로이드. 예중. 졸업. 병창인. 예정. 합격시. 두레소리. 지원. 희망.', '속편. 이정도. 악평. 없음. 추측.', '휴먼. 인심. 좋음. 그러나. 오류. 따라서. 10분. 못넘기겠다.. 어릴적. 봤던. 이필립. 영화. 비교. 나음.', '비교. 선호. 빈도. 높음.', '가장. 영화. 시청중. 음악. 들음.', '시간. 20분. 증가. 아쉬움. 그러나. 짧음. 애니. 선호.', '모성. 준비. 후. 복귀. 모성. 찾기. 과정. 진심. 휴먼.', '영화. 영화. 의미. 없음. 그러나. 다섯군대. 방문. 의미.', '평점. 낮음. 안드로이드. 3점. 제공.', '긍정. 안봄. 꼭. 봄.', '20년.. 인생. 최악. 영화. 명작. 추측됨. 따라서. 영화. 시작. 끝. 없음.', '휴먼. 땅. 먹음.', '원작. 게임. 깊이. 있음. 따라서. 영화. 이야기. 가능. 많음.', '안드로이드. 1위로. 휴먼. 평점. 조짐.', '알라마. 선생. 울음. 안드로이드. 울음.', '마음.. 좋음.', '도둑.. 많음. 따라서. 재미있음. 앞편. 도둑. 몸개그. 약함.', '긍정. 여기. 멋짐.', '안드로이드. 안남. 희망.', '재미있음. 공룡. 공격. 그러나. 장난. 재미있음.', '아직. 귀. 선한. 주제가. 노래.', '대역. 없음. 영화. 예고편. 시청. 차라리. 케이블. 19금. 영화. 시청.', '휴먼. 휴먼. 영화. 처음. 시청.', '평. 좋음. 그러나. 휴먼. 죽음. 예상.', '안드로이드.. 이감. 이유. 모른다. 검색. 후. 확인. 희망.', '시간.우기. 좋음.', '뮤지컬.. 문외한. 안드로이드. 신선한 자극. 영화. 감상. 그리고. 흥분.', '4번. 봄. 따라서. 확인.', '주로. 실화. 기본. 그러나. 시청. 가능. 아버지. 눈물. 시청. 가능.', '공포영화. 심함. 따라서. 볼륨. 작게. 제작. 영화. 스타워즈. 로그. 역. 주인공. 안나 파킨. 출연. 그러나. 눈. 감.', '시나리오. 별. 없음. 배우. 활약. 영화.', '영화.. 다운받음. 시청.', '긍정. 제시카. 사랑함.', '평점. 7. 이하. 영상. 시청. 높음. 따라서. 1점.', '로빈. 제작. 가장. 나쁜 영화. 다수. 시청.', '불가능. 꿈. 꾸는. 철없는. 사람들.', '기대.. 없음. 영화. 자주. 나오길 바람.', '영화. 매력. 영화. 원작. 잘 살리기.', '감독. 새김. 제작. 필요. 제대로. 제작.', '오버연기. 기대.', '복수. 계획.', '좋음. 추천. 영화. 시청.', '우리.. 영화. 기억. 필요.', '평점. 유치함. 있음. 그러나. 몇번. 방문. 명작. 최근.케이블. 복귀.', '긍정.', '재미있음. 그러나. 재미. 없음.', '휴먼. 기만. 시작.', '처음. 두준오빠. 선호. 따라서. 보았음. 그러나. 계속. 좋아짐.', '사랑. 그러나. 섬뜩한. 스토리킹. 20년 전. 변화. 황장군. 단상. 감상.', '재미있음.', '긍정.', '시간.. 남음. 휴먼. 인내심. 필요. 그러나. 감독. 역량. 부족.', '서영희. 미친년. 추측. 그러나. 역활. 그 이상. 보여준. 명연기.', '1인칭. 시점. 화상. 구성. 특이함.', '화면. 예쁨. 따라서. 그.', '재미있음. 이제. 공유. 액션연기.', '재미있음. 처음. 시청시기. 영상. 시청 후. 긴장. 심함. 잔인함.', '지난번. 아동성. 추행. 코드. 왜. 넣었는가. 프레디. 역. 미스캐스팅. 본토. 망각함. 이유. 있음.', '액션신. 재미있음. 그러나. 한국어. 이해. 한국. 외국인. 보면. 구역질.', '기대.. 그러나. 산만함. 따라서. 상영. 불가. 영화.', '정도. 충분함.', '코믹. 드마라. 영화. 재미있음.', '둘 다.. 없음. 아쉬움. 마고. 섬세함. 감정. 섬세함. 여백. 많음.', '보는.. 내내. 가슴. 아픔. 결말. 뻔함.', '끝까지.. 보기. 어려움. 영화. 배우. 연기력. 떨어짐. 따라서. 책 읽기. 어려움.', '영화. 돈OO. 영화. 개봉. 이유. 무엇인가.', '몇몇.. 배우. 어색함. 그러나. 시청. 재미있음.', '영화. 영화. 끝남. 끝남. 끝남. 후. 피아노 연주. 멋짐.', '안드로이드. 안드로이드.', '재미있음.', '하이재킹. 영화. 최고. 추측.', '도라.몽. 비교. 어떤가.', '웃기. 없음. 억지.', '긍정. 휴먼. 동반. 선호.', '부정. 공동체. 부정. 휴먼. 복귀. 상어. 하드코어. 쇼. 시작. 개. 귀여움. 가장. 재밌음.', '초반. 스펙타클. 그러나. 결국. 빛. 좋음.', '깊이. 재미있음. 영화.', '액션. 재미있음. 지루함.', '휴먼. 휴먼. 화이팅.', '한효주. 동생. 사건. 무관. 무관. 역할. 이해. 부족. 아쉬움.', '휴먼. 재미있음.', '휴먼. 이유. 무엇인가. 휴먼. 절대. 보기. 불가. 올해. 최악. 영화. 1순위.', '고맙다..', '내용. 모름. 기무라타쿠. 불사신. 이름. 무엇인가.', '긍정. 더. 가족. 재미있음. 백바. 선호.', '케빈. 작품. 고르기. 안목. 없음. 다행임.', '긴장.. 집중. 시청. 재미있게. 봄.', '화남. 일단. 캐릭터들. 상호. 밸런스. 영화. 비교. 불가능. 그리드. 후. 키르기. 영화. 비교. 액션신. 플레이. 불가. 액션신. 플레이. 시청. 시간. 휴먼. 대체. 휴먼. 영화. 비교. 불가.', '긍정. 학생. 소설. 아님. 그러나. 세상. 편안함. 특히. 빨갱이. 포옹. 논리. 피움.', '몸.. 다른. 존시. 나왔음. 추측.', '부정. 220억.', '휴먼. 아름답다.', '살인게임. 내용. 유치함.', '해당..캣우먼. 팬. 흑역사의. 종류.', '긍정. 그리. 낮은. 점수. 아님. 최소. 7점. 넘어감.', '개재미. 없음. 시청. 권장.', '무심함. 재미. 없음.', '인물.. 관계가. 복잡함. 그러나. 대사들. 깨알같은. 재미. 있음.', '우베볼인. 비교. 훌륭함. 따라서. 우베볼. 영화. 아님.', '긍정. 당연한.', '긍정. 그러나. 그것. 버전.', '5탄. 목격. 확인. 4탄. 그러나. 얼마나. 선전했는가.', '시청.. 불가능. 내용. 모른다.', '재미있음. 특히. 류현경. 배우. 이쁨.', '기가 막다.', '평론가. 평점. 부정. 없음. 휴먼. 6점. 영화. 극장에서. 본다.', '쓰레기. 선호.', '김민. 이쁨. 매력.', '역사. 공부. 어려움.', '맥스페인. 게임. 안해봄. 따라서. 게임. 모르지만. 영화. 나쁘지 않음.', '쓰레기.. 작품. 이해 불가.', '휴먼. 오글거림. 시간. 소모. 영화. 시청.', '이해.. 불가. 그러나. 명작. 확인.', '참신. 스토리. 좋음. 그러나. 점수. 없음.', '90년대. 한국영화. 요런 스릴러. 존재.', '줄거리. 긴장.', '사랑.. 경험. 영화. 최고. 생각함.', '안드로이드. 나이. 먹음. 훌륭함. 동창회. 방문. 가능.', '하정우.', '더럽. 끈적함. 짜증. 그러나. 슬픔.', '명작.', '단지. 동성애자. 혐오. 복장. 성생활.', '멋있다.', '명함. 전. 서극. 숨김. 명작.', '긍정. 치바 유어. 귀여움. 따라서. 100점.', '안드로이드. 재미있음. 추측.', '예상.. 시청 가능. 충분히. 보임.', '꿈. 먹는다. 종. 영화. 시청.', '굿..', '춤.. 추는. 펭귄. 우스운 주제. 아님.', '문화.. 경험. 따라서. 춤. 추기. 과정. 지루함.', '눈.. 찐다. 안구. 포기. 희망.', '후.. 재치. 후. 엔딩. 따라서. 작위성. 흐림.', '간만에. 다시. 시청. 재미있음.', '늦음. 시청. 두 배우. 배우. 연기력. 진정성. 느껴짐. 영화. 좋음.', '의미. 깊이. 생각. 있음.', '휴먼. 허무함.', '재미있음. 시청. 결과. 속음.', '휴먼. 웃음. 영화. 재미있음. 말초. 코미디 영화. 비교. 비교. 재밌음.', '손에.. 묶임. 레슬링 선수. 동반. 격투. 힘듬. 두손. 묶기. 힘듬.', '쓰레기.. 영화. 시청. 이유. 무엇인가. 빵점. 없음.', '드라마.. 시청.', '재미있음. 시청. 후. 끝남. 기다림.', '평점. 9점. 이하. 평점. 없음.', '시청.. 가능. 드라마.', '본드. 역사. 최악. 본드.', '쓰레기 영화. 극혐. 기간. 하품. 영화감동. 없음. 재미. 없음.', '재미있음. 한숨. 나옴.', '재미있음. 봄. 최근. 시청. 그러나. 재밌음.', '처음. 접함. 경험. 없음. 따라서. 영원히. 만남. 없음.', '브루스. 윌리스. 최근. 떡밥. 날림.', '지루함. 극치. 힘듬.', '영화.. 평점. 받기. 힘듬.', '눈물. 웃음. 웃음. 웃음. 웃음.', '시간. 시간. 없음. 확인. 농장. 아닌. 공업. 돼지. 편익. 제외. 무관. 식문화. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관. 무관', '휴먼. 아이디어. 무엇.', '긍정. 긍정. 동반. 프로그램. 참신함.', '드라마.. 방영. 후. 시간. 아쉬움. 그러나. 그 시대. 정치사. 시대적. 상황. 재구성. 가능.', '긴장감. 확인. 평점. 낮음.', '앞뒤. 없음. 논리. 없음. 대신. 허영심.', '예술가.', '영화.. 비교. 비극. 코미디. 스릴러. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디. 코미디.', '영화. 좋은. 그러나. 우연. 많음.', '복수심. 불호. 그러나. 범인. 수준. 상상. 불가능. 평범한. 평범한. 수행자. 됨.', '확인. 그러나. 그렇게. 기억. 남는. 영화. 아님.', '해피. 엔딩. 그러나. 마음. 아픔.', '휴먼.', '재미있음.', '구매.. 어째.', '원작. 재미. 있음. 재미있음. 시청.', '잔잔. 여운. 있음. 커피. 한잔. 희망.', '안드로이드. 인기.', '선우일란. 육덕. 찬양.', '기대.. 그러나. 실망. 기자. 평론가. 의견. 비슷함. 그러나. 나치. 언급. 수준. 아님. 사람. 여러명. 동반. 소꿉놀이기. 시청.', '제목.. 기묘한. 이야기. 선호. 이유. 명확함.', '긍정. 휴먼. 7점. 8점. 그러나. 이 영화. 10점.', '추억..', '기대.. 많음.', '어린.. 사랑. 표현. 영화.', '귀.. 고양이. 노래. 부르던. 중. 노래. 슬펐음.', '긍정. 배우. 능숙한. 연기력. 인간. 감정. 잘 표현.', '볼레. 좋음.', '굿. 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿 굿', '재미있음.', '긍정. 지금. 시청중. 진심. 지루함. 군더더기. 많음. 더빙. 어색함.', '부정.', '긍정. 참여. 2점. 부여.', '아름다운.. 사랑. 목격. 가능. 따라서. 좋음.', '미생 성대리. 착용.', 'BBC. 실망. 안함.', '패배. 아픔. 없음. 희망. 실패.', '주인공. 목격. 시간. 무관. 따라서. 인간. 배반.', '휴먼. 없음. B급. 괴수류. 블랙코메디. 물고기. 종류. 많음.', '클라리. 영화. 시청. 암. 나음.', '해당. 어이상실. 복귀. 최강. 반전. 희망.', '가장. 영화. 기억. 후. 다시. 생각.', '시간. 소모. 필요.', '마지막.. 액션. 없음.', '긍정. 정도.', '재미있음. 감상. 아쉬움.', '추억. 주제곡. 따라서. 10점. 획득.', '원작. 어디인가.', '최근. 영화. 가장. 후회. 영화. 시간. 소모.', '마지막.. 개그. 주성치. 티격태격.', '긍정.', '필요. 없음. 여주. 너무. 예쁨. 넋. 놓고. 감상.', '평점. 시청. 결과. 비교. 좋은. 영화.', '이해.. 그러나. 휴먼. 영화. 시청. 기분. 풀기. 필요.', '따라서. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드.', '무모함. 제작진. 출연진.', '긍정. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이 플레이 플레이 플레이 플레이 플레이 플레이 플레이. 플레이. 플레이 플레이 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이. 플레이 플레이 플레이 플레이. 플레이. 플레이. 플레이 플레이 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이 플레이. 플레이 플레이. 플레이 플레이 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이. 플레이 플레이 플레이 플레이. 플레이 플레이 플레이.', '안드로이드. 선호.', '동전. 그리고. 능력. 있음.', '재미있음. 예상. 그러나. 아쉬움.', '영화. 망각함. 역할. 없음. 그러나. 원래. 선호. 여주인공. 따라서. 끝까지. 시청.', '하나님 사랑. 다시. 경험.', '평점. 높음. 이유. 무엇인가.', '인간. 욕정. 늙음. 죽음. 순간. 사라짐.', '쓰레기. 영화. 시청. 후회.', '긍정. 평점. 낮음. 최근. 사람들. 선호. 동화. 같은. 이야기. 그러나. 재미있음.', '액션물 스릴러. SF. SF. SF. SF. SF. 그냥. 드라마 장르. 아님. 최루성. 멜로. 심금. 울리는 내용. 아님. 그냥. 수면제. 구매. 불가. 수면제. 대신. 지친 몸. 회복. 수면. 수면. 대신. 수면. 대신. 통증. 해소. 수면.', '명절. 단막극. 비슷함. 편함. 재밌음.', '시청.. 그러나. 평점. 높음.', '그때. 추억. 간직.', '아픔.. 목격. 예상. 그러나. 눈. 동반. 억지. 눈물. 흘러감. 억지. 눈물. 흘러감. 억지. 눈물. 흘러감.', '수2. 풀림. 영어단어.200개. 외우기. 기본. 기본. 점. 지급.', '10점. 만점.', '마음. 아픔. 휴먼. 어머니. 더. 잘함.', '휴먼. 무엇.', '재미있음. 한국영화. 9. 점. 매미. 있음.', '만화.. 코스프레. 대비. 연기, 액션. 최상의. 수준.', '긍정. 천국의 아이들. 못봄. 목격. 희망. 감독. 동일함.', '영화. 명작. 따라서. 해당. 현상. 납치. 사람. 돕는다. 어떤가.', '영화. 기억. 안남. 영화.', '아가들. 집중. 보았음.', '어머니. 동반. 1981년. 퀸. 프레디. 머큐리. 만남. 시간여행.', '영화. 교훈. 제공.', '평점. 낮음. 그러나. 후세. 영화. 기대. 감독. 재능.', '주제도 식상. 따라서. 대안. 없음.', '본 사람. 대단함.', '보기.. 선호. 가능.', '죽는가. 이유. 무엇인가.', '캐스터. 캐스터. 고대로. 따옴. 수고. 2점.', '괜찮음. 그러나. 달리기. 중. 부상. 여자. 동반. 최고.', '개미. 공동체. 주제. 영화. 참신함.', '영화. 엔딩. 최고.', '고등학교. 졸업. 안드로이드. 카이스트. 우등생. 오현민. 제압.', '캐스팅. 기대. 그러나. 불친절함. 사람들. 선호. 선문답. 영화. 길이. 길다.', '필요.. 없음.', '실화. 확인. 드래곤볼. 실화.', '재미있음. 왜. 만듬.', '필요.. 영화. 예전. 시청. 뇌리. 각인.', '긍정. 감독. 평점. 낮음. 따라서. 지급. 8~9점. 수작. 그러나. 아름다운 영상. 감상. 즐거움. 사극. 따라서. 선호. 원작. 비교. 안함. 그러나. 감독. 다세포. 초창기. 시작. 그러나. 전반. 결말. 좋음.', '안드로이드.. 추천. 여자. 사진. 한장. 선호.', '재미있음 재밋음. 재밋음. 재밋음.', '안드로이드. 선호.', '가장. 영화. 가장. 선호.', '선호.. 이유. 무엇인가.', '방문.. 희망. 있는가.', '구타유발. 인물. 많음.', '달곰.', '안드로이드.ost. 선호. 장국영. 보고 싶음.', '실망. 실망. 완죤. 선호. 그러나. 이번. 실망.', '레전드. 대단함.', '재미있음. 비교. 안됨. 영화.', '영화. 오랜만. 만남. 좋은. 영화.', '요리사. 머리. 휴먼. 신경. 안쓰는가.', '오늘. 영화. 봄. 옛날. 영화. 보기. 좋음.', '긍정. 마라톤. 영화. 비교. 수준.', '다른.. 성룡 영화. 비교. 덜함. 그러나. 재미있음.', '남편. 휴먼. 눈물. 동반. 마지막. 어머니. 눈. 흐림.', '아토피. 통증. 동반. 태헌. 건강. 기원.', '긍정. 아이디어. 좋음.', '영화. 속임. 1점. 영화. 코미디.', '두 배우. 배우. 대결과. 비교. 너무. 싱거움.', '개.아치. 일. 그린. 레알. 쓰레기 영화.', '일본. 영화. 시작. 민폐. 국가.', '몰림. 죽음. 휴먼. 해피. 끝남. 없는가.', '액션장. 가장. 볼만함.', '의도. 없음. 예상. 가능.', '무엇..', '가장. 웃음. 문제. 풀기. 재미있음. 기대.', '안드로이드.. 이상한 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈. 눈.', '영화. 최근. 돈. 발치. 시기. 달라진다. 따라서. 영화. 시청. 짜증남. 처음. 펜싱. 발치.', '여러명. 삶. 보여줌. 밋밋함.', '재미있음.', '재미있음. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드. 안드로이드.', '잘 모르겠다. 처음. 불쌍함. 그러나. 인간들. 생활. 그리움.', '너무.. 늘어남. 마지막. 10분. 시청. 불가. 미스캐스팅. 따라서. 재미. 없음.', '여태. 본. 영화. 가장. 웃김. 영화.', '표지.. 멋짐. 공포. 유발. 선호. 3류. 영화. 표본.', '야구.. 커플. 동반. 야구. 선호.', '예고편. 속음.', '꿀잼개. 정자. 크기. 무한.', '잊음. 다시. 반가움. 이제. 기억. 하기. 희망. 주문.', '영화. 시청. 내내. 불편함.', '휴먼. 휴먼. 동반. 커플. 졸작.', '휴먼. 아름답다. 그러나. 끝. 이동. 지루함. 이해 불가. 작품.', '아.본지. 오래됨. 기억. 안남. 그러나. SF. 주인공. 동반.', '안드로이드. 재미있음. 평점. 낮음. 명작. 아님. 이정도면. 시청. 가능.', '영화. 개봉. 공포감.', '액션. 내용. 내용. 그러나. 시간. 소모.', '긍정. 최근. 자극적. 한국영화. 무관. 그러나. 최근. 자극적. 한국영화. 무관. 그러나. 이 영화. 같이. 서정적이고. 담론. 따뜻함.', '침몰.. 금지.', '긍정. 시즌3. 시청. 결과. 평점. 3점. 획득. 너무. 감상적. 흘러감. 그러나. 멘토. 동반. 끈적임.', '파파. 거리. 이동. 총. 발치.', '안드로이드. 평점. 부정. 없음. 재밌음.', '영화.. 요소에. 배치. 영상. 압도적. 영상. 그리고. 3일. 이야기.', '재미있음. 시청중. 철수. 효민. 언제. 파이팅.', '가장.. 휴먼. 영화. 가장. 선호. 귀농. 희망.', '재미있음. 그러나. 스토리. 부족함. 다이상.', '감동. 좋음. 예술. 선호. 이유. 다양한. 유혹. 그러나. 마음. 알아줌. 가능함.', '휴먼. 갓. 착용.', '긍정. 이정재. 매력. 보유. 킹왕.', '돈.. 지급. 영화. 제작. 희망. 영화. 제작. 관련자. 모니터. 안받는가.', '재미있음.', '재미있음. 이런. 계열. 드라마. 최고. 작품. 재미있음.', '시즌2. 마무리. 명작. 남기. 계획. 그러나. 억지. 시작.', '긍정. 생각. 없음. 낄낄. 보기. 좋음. 영화. 특히. 제시카. 알바.', '잔잔. 감상. 후. 감상. 즐거움. 오늘. 안드로이드. 영화. 감상. 희망.', '긍정. 성룡. 동반. TV. 시청시간. 많이. 잡아서. 배우들. 고충. 더. 심화.', '잔잔함. 빵. 터짐. 코미디. 진심. 최고. 영화. 그러나. 시간. 큰. 블록버스터. 비교. 2배. 더. 재미있음.', '긍정. 시선. 무관. 시선. 시선. 시선. 시선. 변화.', '다리.. 붕괴장면. CG. 그림판. 검은색. 선택. 탑승. 후. 크랙. 로라. 차. 오른쪽으로. 이동. 중. 부상. 아파트. 붕괴. 상황. 그림판. 가림. 운석 폭파. 장면. 불가. 운석 폭파. 상황. 의도. 연기로. 가림. 운석 폭파. 의도. 운석 폭파. 의도. 불가. 운석 폭파. 의도. 의도.', '주인공. 처음. 피카레스크. 착용. 예상. 그러나. 요즘. 사극. 리터. 풀기. 힘듬.', '억지.. 부정. 착함. 대신. 멍청함. 진주. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀. 복귀.', '대학교.. 영화. 7번. 시청. 질리지 않는. 만점. 영화.', '영화. 돈. 벌기. 목적. 아님. 예술영화. 감상. 재미. 없음.', '영화. 선호.', '휴먼. 따뜻함. 영화. 선호.', '긍정. 재미있음.', '금요일. 예상.', '형제.. 동반. 시청. 반응. 좋음. 애들. 동반. 시청. 희망.', '눈. 즐거움.', '토사물. 쓰레기. 수거. 시간. 소모. 미치겠다.', '서태지. 방가움. 어제. 티비. 시청. 따라서. 자주. 출연.', '백형 감독. 차기작. 계획.', '영화. 가슴. 먹먹함. 좋은. 영화. 그러나. 소모. 힘듬. 따라서. 이 영화. 발견. 감사함.', '해당. 단어. 배우. 연기. 실망. 작품. 힘듬. 감독. 연출력. 실망. 음악. 실망.', '다른.비영화. 백신. 찾기. 혹은. 분노바이러스. 포함. 안됨. 따라서. 좋았음.', '드라마.. 극적. 비현실적.', '몰입. 하나.. 충분함.', '오직.. 감독. 목적. 영화.', '굿바이. 긴장감. 넘치는. 영화.', '지원언. 미자. 연기. 도움. 고마움. 사랑함.', '아직.. 따듯함. 확인. 영화. 소아암. 걸린 아이. 희망. 잃지 않고. 항상. 웃는 것. 배우기. 좋음. 추천.', '스토리. 뻔함. 그러나. 그냥. 홍콩 느와르. 보는 기분. 시원함.', '10점. 사실. 9점. 그러나. 평점. 부여. 휴먼. 공포영화. 장르. 다양함. 그러나. 인간. 심리. 고공. 공포영화.', '유명 배우. 나옴. 영화. 따라가기. 어려움.', 'sf. 특히. 주제. 살림. 불가능. 설정. 암적. 가능성. 있음.', '재미있음.', '좋은.. 찾기. 실패. OO 감독. 연출. 잘함. 영화. 기대.', '보기. 좋음. 동화같은. 이야기.', '영화. 슬픈. 주인공. 박민수. 매니저. 그러나. 가장. 선호. 일. 철없음.', '스타크래프트. 외전. 있는가. 오버로드. 비행기. 공격. 상상. 브루스. 재수없음.', '톰크루즈. 그 당시. 영화. 센세이션.', '영화. 재미있음. 그러나. 예술.', '콩콩. 콩콩. 콩지노.', '보는 것.. 시간. 집중. 시청. 감사함. 영화. 시청시. 철수. 불쌍함. 생각. 그러나. 철수. 행복함. 보여줌.', '이미.. 몽정. 아이들. 좋은. 영화.', '영화.. 시청. 화들음.', '어릴 때. 재미있음. 상영시간. 1시간. 넘어감.', '유치.. 예상. 그러나. 나름. 어린이용. 영화. 스러운 분위기. 살림.', '재미있음. 아쉬움.']\n",
            "           id                                           document  label\n",
            "0      280788                     만족감이 거의 없는 영화, 개에게 큰 한표를 주고 싶다      0\n",
            "1     5086827                               적극추천하고픈 영화입니다 모든분들에게      1\n",
            "2     5289443                 성인버전 느끼 에로 하이틴로맨스물. 허리에손은 뭐하러 나왔나?      0\n",
            "3     7252623                 아주 DREAMS COME TRUE네. 꿈이 이루어져서 좋냐.      0\n",
            "4     9978482  복서의 아내로서 끝까지 록키를 믿고 따르는 에드리안 같은 아내를 얻어야되 정말 최고...      1\n",
            "...       ...                                                ...    ...\n",
            "1120  1757700                              이미.. 몽정. 아이들. 좋은. 영화.      1\n",
            "1121  9712565                                      영화.. 시청. 화들음.      0\n",
            "1122  3399950                        어릴 때. 재미있음. 상영시간. 1시간. 넘어감.      1\n",
            "1123  5749636           유치.. 예상. 그러나. 나름. 어린이용. 영화. 스러운 분위기. 살림.      1\n",
            "1124  1967825                                         재미있음. 아쉬움.      0\n",
            "\n",
            "[1125 rows x 3 columns]\n",
            "['만족감 거의 없는 영화, 개한테도 한표 주고 싶음', '추천하고 싶은 영화임. 모든 분들한테 추천해주실 수 있음', '중학생 버 때 처음 봤던 하이틴로맨스물인데 허리에 손을 대고 뭐하고 나왔음?', '드디어 꿈이REAMS COM TOT! 꿈이 이루어져서 좋음?', '복서의 아내로 끝까지 록키를 믿고 따르는 에드리안 같은 사람 있으면 좋겠당 ᄏᄏ 주제곡도 잼을 거임', '엔딩 잼있네', 'over!', '분명하게건데 왜 만들까? ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ 신주아는 어케하면 7년만에 무슨 영화같은거 찍을뻔 했어?', '남성과하고 여혐 둘 다 포용할 수 있는 페미니즘 영화임', '딱히 아무것도 안 느껴지는 광신도들임', '마리사 토메스의 재회하고 싶음. 좀만 세련되게 만들었음', '나도 예중에서 뛰는 병창인데. 예고때 되면 두레소리에 지원 하고 싶음', '속편이 이정도면 그렇게 악평할 이유가 없는 듯', '너무한한 거 같음. 인심 좋게 볼려고 해도 오글거려서 20분을 못 넘길 듯. 어릴 때 봤던 이필립 에로 영화보다 나을듯', '누가봐해도 ᄌᄂ 하위권임', '가장 극 영화임 ᄏᄏ 도중에 보다가, 음악만 들으면 다 후회할 정도임', '한 시간 30분 정도 더 늘렸으면 하는 아쉬움 있는데 짧고 강렬함 ᄏᄏ...애니 좋아하는 사람이라면 꼭 봐야할 듯', '모성 첨가하기보다 모성을 찾아가는 과정이 잼썼음', '내가 본 영화, 그것도 꽤 오랫동안 상영했네,, 다섯 군데에서 상영했네,,,,', '평점이 낮아서 나도 1점 줘야겠다', '걍ᄋ 좋음. 안 봤으면 꼭 봄 ᄏᄏ', '진짜 20년3년 인생중 가장 나쁜 영화임. ᄏᄏ.', 'ᄋᄋ 너한테도 흙 먹일거임', '원작 게임 자체가 그렇게 깊이 있는 스토리 가지고 있지 않으니까 영화에서 이야기할 수 있는 내용이 많지 않은 건 어쩔 수 없음. 이 영화는 신선함 떨어지지만 최소한 원작을 망친 것도 아니고 내용이 엉성하지도 않았음', '1위는 아니니까 평점 조절이라도 ᄀᄀ', '알라마도 울고 나도 울었음', '마음  ᄒᄒ', '도둑들이 많아서 재밌었음. 앞쪽에서 도둑2명하고 비교하면 약했음', '하이, 진짜 멋있네 ᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '그럼 아무도 안나왔으면 좋겠네', '재밌지. 공룡이 들어옴에도 장난을 친다는게 참담하긴 하지.', '아직 귀 선한 주제가의 노래임', '대역하고 뭐고 영화예고편 자체가 낚시 같으니까 차라리 케이블에서 해주는 19금 단편이 낫지 않을까?', '휴먼 땜에 봤는데 지루하네.보다 꺼버린 영화였음', '진짜 좋였는데 평은 아주 좋음. 지루해서 죽는 줄 알았음', '내가 이 왜 봤는지 모르겠음. 검색 좀 해봐라', '시간 때우는데 좋음', '뮤지컬은한인 나한테는 굉장히 신선한 자극이었음. 그냥 보고 싶으면 보러가라!', '4번정도 봤는데 앎', '보통 실화는 기본인데, 이건 감동의 재미도 있고 아버지 셤플린 이야기 볼만함', '확실히 좀 무서워서 볼륨 작게 해서 본 영화임. 엑스맨 시리즈의 로그 역 맡았던 안나 파킨이 주연을 맡았는데 그 와중에도 눈이 갔어... 일식과 인간을 속이고 빨아들이는 악마. 마지막 7번째 아이에 대한 관객 예상 뒤집기 등 볼만한 공포영화임', '시나리오는 별로인데, 배우들이 살린 영화임', '이 영화 다운받구 보자고', '완전 굿음. 제시카 완전 사랑함', '평점 7.3이 딱인 비디오물인데 너무 높아서 1점 ᄏᄏ', '로긴하게 만드는 영화, 내 인생에서 가장 후회하는 영화들 중 하나일듯 ᄏᄏ', '아무도 할 꿈을 못 꾸는 철없는 사람들임', '별 기대 기대 안하고 봤는데 진짜 최고임. 이런 영화 자주 나왔으면 좋겠음', '언제 봐도 봐도 매력있는 이야기임. 영화 원작이랑 잘 맞았음', '감독님 새기려면 제대로 만들 수 있는거야', '오......', '복수할거임', '짱ᄋ 추천함. 꼭 봐야할 영화임', '우린 이 영화 기억해야함', '평소에 어땠음? 약간 유치한 부분도 몇번 봤는데 명작이네 ᄏᄏ', '짱ᄋᄏᄏᄏ', '재밌지 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '관중들만 웃긴 쇼네...', '완전 두준이가 좋아서 봤는데 엄청 좋아짐 ᄏᄏ', '애절한 사랑에서 찐한 사랑으로 변모한 20년 전,,,,,,,,,,,,', '잼있네', 'ᄋᄋ?', '시간 남는 사람만 인내심 갖고 봐라 감독 역량이 부족함', '아마 서영희 진짜 미친년일지도...그럼에도 역활 그 이상으로 보여준 명연기였음', '한 사람칭 시점의 화소가 참 묘하게 불규칙해서 헷갈림', '화면 참 예뻤는데 그 말고도 다른 화면들도 참 예쁨', '완전 재밌음. 이제야 보니까 공유 액션연기 완전 잼음', '엄청 재밌잼임. 첨에 티비 보다가 갑자기 긴장하고 잼썼음. 잔인하고 무서운 영화들이 많았는데...', '전에 없었던 아동성추행범 코드는 왜 넣었음? ᄏᄏ... 프레디도 미스캐스팅에 본토에서 너무 쉽게 망한 이유가 있는 거 같음', '액션신은 볼만함. 근데 한국어를 알아듣는 한국인이 보면 질릴정도로 찐한 코미디임. 북한 테러리스트들 말이지.', '꽤 기대 기대했는데 산만함 그 자체였음. 그래도 못 볼 영화는 아님', '이 정도면 충분하지~', '코믹하고 드마라가 있는 재밌는 영화임', '둘 다 가질 수 없는 사랑,,, 끝나고 너무 아쉬웠음...마고 섬세한 감정연기는 못잊을거같음', '보는 내내 얼마나 가슴 아팠던지...결말 뻔할 수 밖에 없었어...', '끝까지 보기하기 힘든 영화들. 배우들 연기도 떨어져서 집중이 안됨. 책 읽음', '곧 대박 돈OO 영화임. 왜 흥행이 대재앙인거임?', '몇 명 연기가 어색하긴 했는데, 보다보니 재밌게 봤음', '영화 제목 그냥 쭈욱 끄다가 끝나고 나면 뭐하는 거 같은 기분이었는데 피아노 연주하는 건 멋있었음', 'OOO', '잼잼...', '하이재킹을 소재로 한 영화 중 최고라고 자부할 수 있을 거임', '도라에몽이랑 같이 겜하는거임?', '웃기 않고 억지스러운 쇼는 요즘 세상에 딱히 보기 싫음', '담에 지나가다가 걍 걍 걍 걍 걍 걍 걍 걍 ᄏᄏ', '사회 부 문제점에 미친 놈들이 그냥 돌아가지고 상어가랑 하드코어 쇼한다는 것부터가 거지같고 개 귀여워서 제일 재밌었음', '초반엔 스펙타클한데, 결국엔 빛 좋은 개 꼴이였음', '엄청 재밌롭고 재미있는 영화임 ᄏᄏ', '난 액션션이 지루하다고 생각함', 'ᄋᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '한효주 동생이 아니라 연기가 진짜 겉도는 거 같아서 아쉽고.', 'ᄒᄒ 재미있게 일 할 수 있을 거 같음', '아님. 왜 덧글지? 절대 안 봄. 올해 최악영화 1순위로 뽑음', '고맙...깐! ᆪ강아지하고 같이 나가서 재미있게 놀 줄 알았음', '뭔 내용인지 모르겠네...기무라타쿠야가 불사신임?', '짱ᄋ...짱구가 더 가족적이고 재밌는 거 같음. 이 정도면 7점짜리인듯', '케빈 형님은 걍 작품 고르는 거에 관심이 없으신 거 같음. 그래도 다행임', '긴장하면서하면서 집중해서 엄청 재밌게 봄', 'ᄅᄋ 화나...그럼 일단 캐릭터들간의 밸런스가 영화에서는 너무 어긋나서 그리드 후면 곤키르아는 거미하고 동급이 될거야...', '이건 뭐,,,,,,,,,,,,,,,,,,,,,,,, 진짜 대단한 두뇌들임. 특히 빨갱이들을 감싸주면서 개수작 논리 피우는 우리나라에 있는 두뇌들임', '몸만 다른 존시나 나온 줄 알았음', '아......220억?', '난 아름다름 ᄏᄏᄏᄏ', '살인 게임이 좀 유치하긴 하지', '걍ᄋ...캣우먼 팬들은 그냥 걍 갠적으로 갠적으로 갠적으로 갠적으로 갠적적으로 갠적적으로 갠적', '그렇게 낮은 점수 안주는 것도 아닌데 최소 7점 넘어야하지 않음?', '개재미없다고 보지마', '무심하지도 않고 재미도 없음', '사람간의 관계가 약간 복잡할 수도 있는데 대충 이런 재미가 있음', '우베볼인 거 생각하면 정말 훌륭함. 글구 우베볼 영화 아니더라도 괜찮은 영화임', '당연하지거야 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '글구 그런 버전만 한 번 보여준거임', '5탄 보고나니까 4탄이 얼마나 무서운지 알겠다...1등하고 3등만 해도 엄청 웃긴 거 같음', '못해서서 내용 알 수 없었음...', '엄청 재밌음. 특히 셤 셤 배우가 이쁨', '진짜 기가 막힘 ᄏᄏ', '평론가들 평점이 어이가 없어서 로그인하게 만드네...이게 6점임? 극장에서 본 내 인생에서 가장 극혐인 영화임...', '쓰레기 음...', '김애희 이쁘고 매력있음', '역사 공부 공부함', '맥스페인 게임 안해봐서 게임은 잘 몰겠지만 영화는 그닥 나쁘지 않았음', '너희 쓰레기 작품인데 뭔 말이 필요함?', '너무 오글거림..정말 시간이 아까워서 10분만 보고 꺼버린 영화임 ᄏᄏ', '확실히 이해 이해 못했는데 명작은 분명 있음', '참신하고 스토리 좋긴 했는데, 점수를 줄 순 없는 거 같음', '90년 한국영화에도 요런 스릴러 있었네', '줄거리만 자꾸 치고 나가네', '사랑해 해본 사람이 느낄 수 있게 아주 잘 만드신 영화임. 다들 최고라고 생각하잖음', '나도 나이 먹어보니 믓찌네 ᄏᄏᄏᄏᄏᄏᄏ 또 볼 수 있을까?', '하이,우니까 좋은 거 같음', '더럽하고 끈적하고 짜증나...너무 슬프...', '명작임 ᄏᄏ', '그냥,애들한테는 징그러워. 복장이고 성생활이니까 ᄏᄏ', '진짜 멋있네 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '명불허전 서극의 숨은 명작임 ᄏᄏ', 'ᄋᄋ 치바 유다이가 엄청 귀엽게 나왔네 ᄏᄏᄏᄏᄏᄏᄏ 100점 ᄏᄏ', '나만 엄청 재밌었던 거 같음', '의외로 볼만함. 충분히 봐줄 수 있을 듯', '꿈 먹고 먹고 삽시다. 영화도 찍을 수 있음', '굿모', '춤 추는 펭귄이라는 주제만 가지고는 안되겠네', '걍ᄋ...춤 추는 과정이 너무 지루함...', '눈  땜에 안구 땜시 영구 포기하고 싶음', '후반부에서 보여준 재치있는 발상하고 달짝지근 엔딩으로 작위성 좀 흐리게 했음', '간만에 다시 봐도 잼슴', '늦엇 봐도 볼수록 두 배우의 연기력 그리고 진심성이 느껴지는 영화임 ᄏᄏ', '의미있는 엄청 깊음. 생각있는 사람이라면 알겟네', 'ᄅᄋ...무서움...', '진짜 재밌게 본 작품인데...속았겠네', '웃긴 영화 ᄏᄏᄏᄏᄏᄏᄏᄏ 말 많고 코미디 영화보다 더 재밌음', '손에 묶이인 상태에서도 레슬링 선수하고 싸우는게 진짜 힘드네;;;;;;;;;', '진짜 쓰레기 같은 영화 다 봤는데 왜 빵점이 없음?', '드라마로으로 해보고 싶음', '재밌어 보는 내내 언제 끝나나 기다림', '평점 평점이 9점 아님', '보고 또 볼만한 드라마임', '역사는 본드...', '그냥 쓰레기 영화 넘 재밌어보이는데...하필 하품나던 영화감동도 안하고 재미도 없었음  ᅲ', '엄청 재미 재미없네...한숨이 옴...', '엄청 재밌게 봤음. 예전부터 봤는데 이젠 다 봄 ᄏᄏ', '첨에 접하는 사람들은 영원히 다시 접하지 않을 듯', '브루스스 윌리스를 보면 왠지 웃음이 나오는데, 요즘에는 떡밥이 너무 많이 날린다고 생각함. 브루스에 나왔을 때 평점도 안주고 받았더니...', '지랄한 거 같음 ᄏᄏ 힘들었음', '왜 국내 영화는 평점 받기가 힘든거임?', '눈물도 있고 웃음도 있고 괜찮았던 영화였음', '시간 가는 줄도 몰랐음. 농장에서 아닌, 공장에서 축산물로 만든 건 그 어떤 것들도 우리한테도 안좋아하는 거임. 식문화와는 절대 무관한 우리 인간들이 꼭 알아야할 부분들 잘 말해주는 영화였음', '무슨 생각 만들었음?', '감동적인 면도 있고 프로그램 자체가 참신한 거 같음', '그 동안에 빠져서 시간 가는 줄 몰겠는데 이젠 아쉽네...그 시대 정치사의 시대적 배경을 되돌아볼 수 있었던 것도 재밌었음', '긴장감 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '앞뒤도 안맞고 논리도 없고 대신 허영심에 찌든 히어로 영화임 ᄏᄏ', '예술가?', '네이버 영화에 대한 설명인데, 비극과 코미디, 스릴러와 로맨스를 아우르는,,,,,,,,,,,,,,,,, 대단한 배우들!', '좋은 영화인데 우연들이 너무 많음 ᄏᄏ', '확실히 복심에 불타는 건 인정하는데, 범인의 수준에서는 상상도 할 수 없는 일이니까. 무협지도 아니고 평범한 애가 갑자기 007급 능력자가 되나?', '보긴하긴 했는데, 그렇게 강렬하게 기억에 남는 영화는 아니었던 거 같음', '해피엔딩인데 마음 씀씀...', '별로 안 있음', '잼있네', '어케서 사려고 함?', '원작 나름 재미있게 구운 거 같음 잼게 봄', '잔잔하고 여운있는 영화였음. 커피 한잔하고 싶네', '나도 신기기대...', '선우일란의 덕을 찬양해라', '기대하면서 했는데 진짜 실망했음. 기자들처럼 시작은 엄청 강렬했음. 근데 나치 언급할만큼 거대한 디비전이 있는 건 아니였음. 사람 여러명이서 소꿉놀이를 하는 거 보다 더 나을듯', '제목대로 기묘한 이야기 말하는 거에 대한 호불호가 분명 있음', '또라이들이네,, 누가 7점 8점이라고 했음? 이 영화는 10점임', '추억이게 ᄏᄏᄏ', '기대하고 있었는데었는데...', '어린애들의 순진함을 그린 영화임', '귀여운 고양라미 노래 부르던 애가 슬펐던 거 같음', '감탄 배우들 연기로 인간 본연의 감정을 잘 표현하고 있음', '볼레로 정말 좋았음', '굿 굿 굿 굿', '완전 재밌었음', 'ᄋᄋ 지금 보고 있는 중이긴한데 진짜 지루하고 군더더기가 많음. 더빙인데 어색하고 톤이 빡셈', '걍ᄂ', '나도 그풍에 2점 준다고 함', '예쁜 사랑 볼 수 있어서 좋았음', '미생 성대리가 쥔 공이네', 'BBC는 실망하지 않았음', '1점도 아깝지 않음?', '엥ᄋ 이거 완전 주인공인거 같음. 지상에 눈 멀어서 인류를 배반하는 거 아니냐', '아무 생각 없이 볼 수 있는 B급괴수류 블랙코메디아임', '클라리 ᄏᄏ 이 영화 보고 암이 나았음', '그럼 어 어이상실 가보자고. ᄏᄏ...최강 반전이 올거임', '최고 영화 영화라곤 다 잊고 있었음. 어느 순간 다시 생각난 거 같음', '시간 아깝네', '확실히 마지막액션 말고는 볼 거리가 없었음', '그건 좀네 ᄏᄏ', '글케 재미있게 읽을 수 있는 책이였으면 좋겠네 ᄏᄏᄏᄏᄏᄏᄏ', '내 추억과 주제곡 땜에 10점 만점에...', '원작 어디감?', '최근에 본 영화 중에서 가장 후회되는 영화임. 시간이 아깝다고 느낀 적은 있음', '마지막까지 하는 주성치! 티격태격하는 주성치!', '무슨 일?', '다 필요고 여 주인공 너무 예뻐서 넋놓고 봤음', '평점 보고 봤는데 진짜 좋은 영화였음', '이해는 되는데 감당이 안되네...옥희영화 보면서 기분 풀어야지', '그럼 남는 남는 건,,,,,공화당 찍으세요,,,,,이민자 조심해야겠네', 'ᄅᄋ 무모해 보이네... 제작진도 출연진도 ᄏᄏ', '윙가...디움 레비야!', '그래?', '동전하고 남자도 능력이 있음', '재밌을 줄 알았는데 진짜 별점이 없네', '너무 왜곡해서 망한 영화, 역할은 맘에 안들지만 원래 좋아했던 여주인공 땜에 끝까지 봤음', '하나님의 사랑 다시 경험한 시간임', '왜 이렇게 평점이 높음?', '인류의 욕정은 늙어서 죽어나갈때까지 사라지지 않는 거 같음', '쓰레기 같은 영화네 ᄏᄏ 진짜 영화 보다가 후회함...', '어째서? 평점이 낮음? 요즘 사람들이 동심이 없나봐. 동화같은 이야기도 꽤 재밌다고 생각하는데 코믹은 없는거 같음.', '이 영화는 액션물도, 스릴러도, SF도, 아니 그냥 드라마 장르일 뿐이지, 최루성 멜로도 심금을 울리는 내용일 수 없음. 그냥 의사가 처방에 따라 살 수 있는 수면제를 대신해서 지친 몸 쉽게 풀어주는 수면 영화임', '설날하는 단막극 같네 ᄏᄏ 엄청 편하고 재밌는 영화임', '볼만 있는데 평점이 너무 높음...', '내가 오 왔던 그때를 간직할게', '슬픈 곳이 어딜까 생각했는데 갑자기 눈물이 흘러나와서 억지로 울게 하는게 아니라 진짜 진심 슬프게 만드는 영화임 ᄏᄏ', '그걸 보고면 수2 풀고 영어단어200개 정도 외워주겠네, 점수를 줄 수 없어서 1점 줄게.', '10점 만점에 10점 ᄏᄏ', '마음  ᄅᄋ 슬프네...엄마한테 더 잘해야지 ᄏᄏ', '무슨 일임?', '잼찌당. 10점 준거중에 한국영화는 9점 주는데 매미영화는 9점 주네', '만화 코스피스를 넘어서서 연기, 액션이 최상의 컨텐츠임 ᄏᄏ', \"아 ...따듯하네...'천국의 아이들' 못보는 건 꼭 봐야지 ᄏᄏ 같은 감독임 ᄏᄏ\", '영화는 명작인데, 여기서 나온 거임. 여기서 나온 거임. 납치된 사람을 돕는 현상은 뭔 일임?', '글구...아무것도 기억 안나는 영화임', '처음으로 아가들이 집중해서 봤네', '엄마하고 함께 1981년에 퀸하고 프레디 머큐리 만나는 시간여행 가실 ᄏᄏ', '참된 교훈 준 영화임', '평점은 낮지만 후세들에 기록될 매니아적인 기발한 영화임. 감독 젤 재능있음', '주제도 식상해서 딱히 대안이 없음...', '이거 본 사람도 대단하더라', '보기 전에 좋은 선택이였길 바랄게', '죽음?', '캐스터 셤 ᄏᄏ 캐릭터 고대로 따오느라 수고스러워서 2점 줌', '괜찮은 거 같던데, 달리다가 쳤을 때 여자 반응이 최고였음.', '개미 사회를 주제로 한 영화라 참신했음', '영화사에서 최고의 엔딩 씬 아닐까? 웃기면서 마지막에 울리는 감동이랄까?', '고등학교 졸업 졸업하고 나선,,, 카이스트 우등생 오현민 놈을 제압하는 건 진짜 웃긴 일임 ᄏᄏᄏ', '캐스터에 기대했는데 너무 불친절하고 불쾌해서 사람들이 욕할만 하네... 선문답 같은 영화인데 길이까지 이렇게 길다니...', '그럴 필요 없음', '이게 실화면 드래곤볼도 실화임', '잼찌다.. 왜 만듬?', '말이 필요? ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ 진짜 예전에 봤던 영화임 ᄏᄏ', '그치. 평점이 생각보다 낮아서 주는 거고 8~9점정도로 수작이긴한데, 아름다운 영상이랑 Ost를 보는 것도 즐거웠음.', '내가 추천한 사진 한장 보는게 낫다고 추천하는게 어땠음? 알바하는게 이런거라고 생각했음', '재밌음 재밋음 ᄏᄏᄏᄏᄏᄏᄏᄏᄏ', 'ᄒᄋ', '가장 좋아하는 영화임 ᄏᄏ', '좋아하긴 왜?', '멀리 싶은거야? 한번 가보겠음', '짜증하는 구타유발 인물들이 너무 많이 나오고 있음', '달곰하다', 'ost가 너무 좋아. 장국영 보고 싶음', 'ᄅᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '레전드는 대단하네 ᄏᄏ', '재밌만만 쫒아내서는 안될 영화임', '오랜만에 만난 영화로 만나서 반가움', '요리사가 머리카락 신경쓰이진 않음?', '오늘 봤봤는데 옛날 영화치고는 볼만 했음', '그건 뭐, 마라톤하는 영화랑 비슷한 수준임', '다른 성룡 영화에 비하면 좀 덜하긴한데 그래도 재밌음', '남편이 울울 때 울음 땜에 마지막 어머니 뵈었을 때 울음 ', '아토피하고 치질로 고생하는 태헌이 치료해주길 바람', 'ᄋᄋ...', '장르 속여서 1점 영화는 분명 코미디임', '두 배우 대결치고는 너무 싱거워서...', '강아지이들 일상을 그린 레알 쓰레기 영화임', '일본 영화 영화부터 민폐인 나라임', '몰리는 왜 죽음? 좀 해피하게 끝나면 안됨?', '액션장면 볼만함', '그 의 의도는 안봐도 뻔함', '뭔데임?', '가장 웃 웃긴 이야기 풀어나갈 수 있는게 아닐까?', '한국 애들한테 이상한 눈으로 보게 만들어준 영화임', '이게 영화인가? 요즘 같은 시대에 돈은 얼마나 많이 썼는데 그걸 보고 짜증이 난 건 처음임. 펜싱은 발목 잡는 운동인듯.', '여러 사람 보여줬을 뿐이지 걍 밋밋함', '잼찌네 ᄏᄏ 잼있음 ᄏᄏ', '너무 재밌음. ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '잘 몰겠음. 첨엔 엄청 불쌍했는뎅,, 그래도 인간들이랑 생활 그리워한다는 느낌은 안들었음. 인간들이 님 이용하긴 한데, 과연 그게 불행이였을까?..', '너무 길게서 7번이나 걸었네, 마지막 10분의 열정이야 말로 미스캐스터같을 정도로. 주인공들이랑은 잘 맞지 않음.', '여태까지 본 외국 영화 중에서 가장 웃긴 영화임', '표지 멋있음 ᄏᄏᄏ 그냥 공포 유발하고 싶은 3류 영화 표본임 ᄏᄏᄏ', '야구는랑은 커플링이랑 같이 하는거임', '예고편 속았음', '꿀잼 개꿀잼 정자 엄청 좋더라 ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '잊고 있었는데 다시 보니까 진짜 반가웠음. 이젠 다시 보려고 주문했어', '보는 내내 내내 불편한 영화네', '하워하고 데이브...멜로사 너무 잘했음 ᄏᄏᄏᄏ', '소피마르소! 근데 끝까지 가면 지루하고 이해하기가 힘든 작품임 ᄏᄏ', '아,지 오래되어 기억이 잘 안나는데 어쩐지 SF하고 비슷한 면이 있었음', '난 재밌었는데 평점이 너무 낮네...명작까지는 아니더라도 이정도면 볼만 할 듯', '이 영화 개봉한다는게 더 공포스러움...', '액션도 내용도, 내용도, 시간도 아까움...', '내 생각엔 요즘의 몇몇 자극적이고 공상적인 한국영화보다 이 영화처럼 담백하고 현실적인 내용을 따뜻하게 담는 영화가 진짜 좋음', '그냥...해상만 떠나라.', '대단하네. 시즌3니까 평점 3점 줘서 너무 감상적인 것 같음. 멘티하고의 관계가 너무 끈적함.', '파파 거릴때마다 총으로 쏴 죽이고 싶었음', '네이버 평점은 진짜 기대 안되는 거 같음 ᄏᄏᄏ 엄청 재밌게 봤음', '영화 요 요소에 배치되어있는 영상들...완전히 빼먹을 수 없는 3일간의 이야기임', '엄청 재밌겠다.. ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '최고로 영화라니깐! 귀농하고 싶음', '잼ᄋ...아무것도 없는 듯,, 뭔가 스토리도 없고 너무 복잡하고...', '감동 주는 좋은 영화네, 예술하는 사람들 여러가지 이유로 유혹이 많지만 마음을 알아주는 사람을 만났으니 운이 좋네 ᄏᄏᄏᄏᄏᄏ 재밌게 봤음. 남 배우님 차분한 목소리 좋음', 'ᄋᄋ 진짜 오~마스 갓이네', '이정재도 매력있는 킹왕이라니깐! 이정재의 연기가 진짜 멋있어', '돈주고 이런 거 만들고 싶음? 영화 제작자분들은 모니터 안해?', '잼있음', '스릴만하네, 이런 계열 드라마 중에선 젤 재밌어', '시즌2에서 깔끔하게 끝났으면 더 명작이 되었을텐데 자꾸 억지로 전개를 하는 거임', 'ᄒᄋᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '잔잔한 감동의 영화 보고나서 감동이였음. 오늘 장진영 영화 보고 싶음', '이정재의 성룡이랑 같이 어딜 가는데 그렇게 늦게까지 서서 배우들 고충을 더럽게 하냐?', '잔잔한 감동, 빵빵 터지는 코미디까지 있는 진짜 영화라고 생각함. 쓸데없이 큰 블록버스터보다 2만배는 더 잼음', '딱히했던 다섯가지 시선들...내가 바라본 세상...', '다리가 붕괴장면에서는 CG가 그림판에 검은색을 선택하고 오른쪽으로 가다가, 로라는 차에서 내려서 오른쪽으로 가다가, 아파트가 붕괴되는 부분도 그림판에서 가림. 운석 폭파장면도 할말이 없음.', '주인공 보고보고 처음엔 피카레스크도 하는 줄 알았는데, 아니더라. 요즘 사극은 다 리터 풀고 보는 재미도 없음 ᄏᄏ', '억지럽게도 착하지 못해서 멍청한 진주가 잭회장에 시원하게 복종하는 거 보여주는 거임', '대학교때 때 이 영화 7번 봤는데 질리지 않는 만점 영화임 ᄏᄏ', '영화 뭐 돈 벌기 위한 영화가 아니야? ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ 평점 봐봐', '걍ᄋ...이런 영화 좋아함', '진짜 따뜻하고 괜찮은 영화임', 'ᄋᄋ 재밌네', '오늘 아침가면 엄청 기대됨 ᄏᄏ', '애들들 데리고 봤는데 다들 반응이 좋더라구! 애들 데리고 보러 가보라고 ᄏᄏ', '눈이 즐거웠음', '토사물 똥쓰레기 시간 아까워서 못치우겠음...', '서태지씨 방가워서 어제 티비 잘 봐서 자주 나오려고 해', '백형 감독님 차기작 해야함 ᄒᄒ', '가슴 먹먹...너무 좋은 영화인데...너무 소모하게 하는 영화라니...이 영화 만난 거 ᄏᄏ', '딱히 말해서,, 배우들이 연기에 실망하고 뭐든 할 줄 아는 감독의 연출력에 실망하고 특이한 소재 못살리는 영화에 실망하고 심지어 음악까지 실망할지도...', '다른 좀비영화에 무조건적인 백신 찾기, 분노바이러스가 이렇게 안되어도 되게 해줘서 좋았음', '아 진짜 드라마라니,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, 이런 평점글 드라마를 보면서,, 난 태어나서 첨까지 남겨봤는데 별 한 개도 아깝지 않음', '몰입 하나만으로도 이 영화는 충분했음', '이건 감독 감독만 위한 영화임', '굿 굿! 긴장감 넘치는 영화임', '지원언 미자 연기해줘서 ᆪ ᆪ ᆪ 사랑해 ᄏᄏ', '아직 세 따듯하다는 걸 느끼게 해줬던 영화였음. 소아암 걸린 아이가 희망을 잃지 않고 항상 웃는 거 보면서 많은 걸 배웠음', '이야기는 뻔한데 그냥 홍콩 느와르 보는 기분이라서 시원함', '10점 만점에 10점 정도임. 사실 9점정도인데. 내가 본 공포영화 중 가장 무서운 영화임.', '유명한 배우가 나와도 영화가 따라주지 못하는 거 같음', 'sf는 특히나 주제가 잘 안 풀리는 설정은 암적요인임', '재밌을 ᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '좋은 소 살린 OO 감독. 연출만 잘 했어도 대단한 영화였을텐데...', '글케 보기 좋네,, 동화에 나오는 이야기들임', '진짜 슬픈 영화 중 하나임. 어쩌면 내 인생에서 가장 찾고 싶은 사람이 박민수 매니저일 수도 있음.', '스타크래프트 외전? 오버로드가 비행기를 공격해서 상상이 안되는데 브루스 재수없어', '톰크루즈 그 당시 진짜 이 영화는 엄청 인기있었음', '영화도 재밌지만 ost 잼슴', '콩이이 콩신 콩신', '보는 순간마다 푹 빠져서 재밌게 봤음. ᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏᄏ', '벌써 몽정한 애들한테 좋은 영화임', '1편 보고 왔는데 화들었음', '어릴 때 엄청 재밌게 봤던 시리즈임. 상영시간 1시간 넘었음', '엄청 유치할 줄 알았는데...그냥 그쪽의 영화로 대체해서 스러운 분위기 제대로 살린거임', '글케 그렇게 재미 없을 줄 몰랐음...무슨 실망함?']\n",
            "           id                                           document  label\n",
            "0      280788                     만족감이 거의 없는 영화, 개에게 큰 한표를 주고 싶다      0\n",
            "1     5086827                               적극추천하고픈 영화입니다 모든분들에게      1\n",
            "2     5289443                 성인버전 느끼 에로 하이틴로맨스물. 허리에손은 뭐하러 나왔나?      0\n",
            "3     7252623                 아주 DREAMS COME TRUE네. 꿈이 이루어져서 좋냐.      0\n",
            "4     9978482  복서의 아내로서 끝까지 록키를 믿고 따르는 에드리안 같은 아내를 얻어야되 정말 최고...      1\n",
            "...       ...                                                ...    ...\n",
            "1495  1757700                                 벌써 몽정한 애들한테 좋은 영화임      1\n",
            "1496  9712565                                     1편 보고 왔는데 화들었음      0\n",
            "1497  3399950                  어릴 때 엄청 재밌게 봤던 시리즈임. 상영시간 1시간 넘었음      1\n",
            "1498  5749636   엄청 유치할 줄 알았는데...그냥 그쪽의 영화로 대체해서 스러운 분위기 제대로 살린거임      1\n",
            "1499  1967825                       글케 그렇게 재미 없을 줄 몰랐음...무슨 실망함?      0\n",
            "\n",
            "[1500 rows x 3 columns]\n",
            "['만족감이 거의 없는 영화, 개한테도 한 표 주고 싶어 ( • ω •́ )', '추천하고 싶은 영화야! (★‿★)', '내 생각엔 성인버전이라고 하더라. 허리에 손을 얹고 나왔어 ( • ω •́ )', '드디어 꿈이! ( ́`) 꿈이 이루어져서 좋음? (⊙_⊙)?', '복서의 아내로 끝까지 록키를 믿고 따르던 에드리안 같은 사람이 필요해 (★‿★) 주제곡도 최고야!                                                                                                                                                                                                                                                                                                                                                                        ', '엔딩 잼있어! (★‿★)', 'o(!', '분명하게건데 왜 만들까? (⊙_⊙)?', '남성과여성과 페미니즘 영화 다 볼 수 있는거야 ( • ω •́ )', '별로 인기 없어 보이는 광신도들인데 (゚▽゚)ノ', '마리사 토메스의 재회하고 싶어 ( • ω •́ )', '나도 예중에서 준비하고 있는 병창이야! ( ́`) 예고에 합격하면 두레소리에 지원 하고 싶어 (★‿★)', '이 정도이야...(⊙_⊙;) 그렇게 악평할 일은 아닌 것 같아 (⊙o⊙)', '너무 한한거야! 아무리 인심 좋게 봐도 오글거려서 20분을 못 넘길 것 같아 ( ́`) 어릴 때 봤던 이필립 에로 영화가 훨씬 나을 듯 ( ́`)', '누가봐봐도 하긴...w(゚Д゚)w', '가장 나쁜 영화야 ( ́`) 도중에 봤는데...음악만 전부 들었을 뿐이였어...(⊙_⊙;)', '한 번 30분 정도 더 더 했으면 하는 아쉬움도 있는데 짧고 강렬하다고 생각해 ( y▽, ) ', '모성을 처음부터 가지기보다, 모성을 찾아가는 과정이 인상깊었어 ( • ω •́ )', '내가 본 영화라니...6군 대전을 봐야겠네 (゚▽゚)ノ', '평점이 낮아서 나도 1점 줘야겠다 (゚▽゚)ノ', '그건 좋은 좋네! ( ́`) 안 봤으면 꼭 봐야겠다 (★‿★)', '진짜 20년3년 인생 중 가장 나쁜 영화야! ( ́`)', '응!! 너한테도 흙을 먹일게! ( ́`)', '원작 게임 자체가 그렇게 깊이 있는 스토리라서 영화에서 이야기할 수 있는 내용이 많지 않은 건 어쩔 수 없는 일이야 (⊙o⊙)', '1위는 아니야! 평점 조절이라도 해줘 (゚▽゚)ノ', '알라마도 울고 나도 울었어 (゚▽゚)ノ', '마음씨가...(⊙_⊙;)', '도둑들이 많아서 재밌었어 ( ́`) 앞편에서 도둑 2명은 몸개그를 해서 강했어 ( ́`)', '엄청 멋멋지당! ( ́`)', '안나왔으면 좋겠네 (⊙o⊙)', '엄청 재미있 재미없어 ( ́`) 공룡이 들어와서 장난을 치는데 어떻게 장난을 쳤어? (⊙_⊙)?', '아직 귀에 선한 주제가야 ( y▽, ) ', '대역하고 뭐고 영화예고편 자체가 낚시하러 가는 거보다는 차라리 케이블에서 해주는 19금 단편이 낫지 않을까? (⊙_⊙;)', '휴먼 때문에 봤는데 지루하네. (⊙o⊙)보다 꺼버린 영화야 (⊙o⊙)', '진짜 별로였는데 평소에 엄청 좋아해. ( ́`) 지루해서 죽는 줄 알았어...(⊙_⊙;)', '내가 이 봤는지 모르겠다...(⊙_⊙;) 미리 검색해보고 가보는게 어떰? (⊙_⊙)?', '시간 때우기에 좋은 것 같아 ( • ω •́ )', '뮤지컬은외한인 나에게는 굉장히 신선한 자극을 준 영화야! ( y▽, ) ', '4번정도 봤는데...(⊙_⊙;) 그래서 알았어 (⊙o⊙)', '보통 실화는 기본인데, 이 영화는 재미도 있고 아버지 눈물의 재미도 있어 ( y▽, ) ', '확실히 좀 무서워서 볼륨을 작게 해서 본 영화야 ( y▽, )                                                                                                                                                                                                                                                                                                           ', '시나리오는 별로인데, 배우들이 살린 영화야 ( • ω •́ )', '이 영화 다운받구 보자고! (★‿★)', '완전 굿! 제시카 완전 사랑해! (★‿★)', '평점 7.3이 딱인 비디오물인데 너무 높아서 1점 (゚▽゚)ノ', '로또하게 만드는 영화 중 하나인 내 인생에서 가장 나쁜 영화야 ( ́`)', '아무도 할 꿈을 못 꾸는 것 같아 (⊙o⊙)', '별로 기대 안하고 봤는데 진짜 최고야! (★‿★) 이런 영화 자주 나왔으면 좋겠어! ', '언제 봐도 봐도 매력있는 이야기야 (  ‘I  ;) 영화가 원작을 잘 살려서 (  ‘I  ;)', '감독의 말이은...새기들을 만들려면 제대로 만들어라! (゚▽゚)ノ', '오버! (゚▽゚)ノ', '복수는할 거야! (★‿★)', '좋앙! 꼭 봐야할 영화야! ( y▽, ) ', '우리는 이 이 영화를 기억해야 해 ( ́`)', '평소에 어땠어? (⊙_⊙)? 약간의 유치한 부분도 있었어도 몇번을 봐도 명작이였어 (⊙o⊙)', '응,! (゚▽゚)ノ', '재밌지 너무 재미가 없어 ( ́`)', '관중들만 보고 가겠네...(⊙_⊙;)', '완전 두 두명이 좋아서 봤는데 엄청 좋아졌어 (゚▽゚)ノ', '사랑스러운 아니라 섬뜩한 스토리킹이야...(⊙_⊙;) 20년 전 부터 나온 소설이야 (⊙o⊙)', '재밌네! ( ́`)', '그래?? (⊙_⊙)?', '시간 남는 남는 사람만 인내심을 가지고 봐야지...감독이 부족해 ( y▽, )', '서영희라는 캐릭터는 진짜 미친년일지도 몰러! 그만큼의 역활을 보여준 명연기자야! ( • ω •́ )', '한 사람칭 시점의 화질은 참신하지만 왠지 답답한 느낌도 있어 ( y▽, ) ', '화면은 참 예뻐 ( ́`)그거 말고도 다른 화면들도 참 예뻐 ( ́`)', '완전 재밌다! ( ́`) 이제야 보니까 다행이네! ( ́`) 공유 액션연기 완전 짱이야 (゚▽゚)ノ', '엄청 재미있잼! ( ́`) 처음엔 엄청 긴장했었는데,,, 잔인하고 무서운 영화들이 계속 나오니까 무서웠어...(⊙o⊙;)', '전에 없었던 아동성추행범 코드는 왜 넣었어? (⊙_⊙)? 프레디역도 미스캐스팅에 본토에서 너무 쉽게 망한 이유가 있는거야 (⊙_⊙;)', '액션신은 볼만해. 근데 한국어를 알아듣는 한국인이 보면 질릴 정도로,,,,,,,,,,,,,,', '꽤 기대 했는데 산만해서 못 봤어...(⊙_⊙;)', '이 정도면 충분하지~( ́`)', '코믹과 드마라가 한데 섞인 재밌는 영화야 ( y▽, ) ', '둘 다 가질 수 없는 사랑이라니...그래도 너무 슬프다...마고의 섬세하고 슬픈 감정연기는 못잊을 것 같아...(⊙o⊙;)', '보는 내내 얼마나 가슴팍이 아팠던거야? (⊙_⊙;) 결말이 뻔할 수 밖에 없으니까...(⊙_⊙;)', '끝까지 보기하기 힘든 영화들 때문에 배우들이 연기가 안되면서 집중이 안됐어 (⊙o⊙)', '곧 개봉OO 영화야! 왜 흥행이 대재앙인거야? (⊙_⊙)?', '몇 명 연기가 어색하긴 했는데, 보고 보니 재밌게 봤어 ( y▽, ) ', '영화 자체가 그냥 계속 끄는 거 같았는데, 끝나고 나면 뭐하는 기분이었어 ( y▽, ) ', 'O(OIL)O', '재밌어! ( ́`)', '하이재킹을 소재로 한 영화 중 최고라고 자부할 수 있어 ( ́`)', '도라에몽이랑 같이 요미하다고? (⊙_⊙)?', '웃기 않고 억지스러운 쇼는 요즘 세상에 딱히 없네 ( y▽, )', '내 생각보다 빨리 끝나버렸어 (゚▽゚)ノ', '사회 부조리에 미친 놈들이 그냥 돌아가지고 상어가랑 하드코어 쇼한다는 것부터가 거지같고 개미미해서 가장 디테일한 쇼라고 생각해봐! ( y▽, ) ', '초반에는 스펙타클한데, 결국엔 빛 좋은 개로 돌아오는 거 같아 (゚▽゚)ノ', '엄청 재밌롭고 재미있는 영화야 ( y▽, ) ', '난 액션션이 지루하다고 생각해 ( ́`)', '너도 화이팅! (⊙_⊙;)                                                                                                                                                                                                                                                                                                                                                                                                                               ', '한효주 동생이 아니라 연기가 정말 겉도는 거 같아서 아쉽다...(⊙_⊙;)', '안녕!~( ▽ )', '왜 덧글지? (⊙_⊙)? 절대 안봐! (⊙_⊙)?', '고마워! ( ́`) 강호동 나가고 나서 재미있게 놀아 (゚▽゚)ノ', '뭔 내용야? (⊙_⊙)? 기무라타쿠야가 불사신이야? (⊙_⊙)?', '너가 더 가족적이고 재밌는 거 같아 ( ́`) 근데 이 정도는 많이 주면 7점인 것 같아 (゚▽゚)ノ', '케빈형은 작품을 고를 줄 아는 안목이 없어. 그래도 다행이야 ( • ω •́ )', '긴장하면서하면서 집중해서 엄청 재밌게 봤어 ( • ω •́ )', '엄청 화났어! 일단 캐릭터들간의 밸런스가 영화에서는 너무 어긋나버렸어. 그리드 후면 곤 키르아는 거미랑 동급이 될거야! (⊙o⊙)', '이건 뭐,,,,,,,,,,,,,,,,,,,,,,,,,,,, 특히 빨갱이를 감싸주면서 개수작 논리 피우는 우리나라 대통령이라니...', '몸만 다른 존시들이 나온 줄 알았어 ( ́`)', '아깝...220억이야! (⊙_⊙;)', '난 아름다다! (★‿★)', '살인 게임이 참 유치하단 말이야 ( • ω •́ )', '그치 팬들은 그냥 자기네들끼리만 흑역사를 써 (*°▽°*)', '그렇게 낮은 점수인 건 아닌데 최소 7점 정도는 넘어야하지 않을까? (⊙_⊙;)', '개재미 없네? (⊙_⊙;) 보지마! (▽)', '무심하지도 않고 재미도 없거든 (゚▽゚)ノ', '사람 간의 관계가 약간 복잡할 수도 있는데, 대사에 따르면 재미있는 것 같아 (  ‘I  ;)', '우베볼인 거 생각하면 정말 훌륭해! ( ́`) 그리고 우베볼 영화 아니더라도 괜찮은 영화야! (▽)', '응, 당연하지! ( ́`)', '응, 그치 한 번 더 한 버전일 뿐이야 ( y▽, ) ', '5탄 보고 나니 4탄이 얼마나 선전했는지 알 수 있겠다. (⊙_⊙;)', '못해서서 내용 알 수 없었어...(⊙_⊙;)', '엄청 재밌어! ( ́`) 특히 류현경 배우가 이쁘지! (★‿★)', '진짜 기가 막혀...(⊙_⊙;)', '평론가들의 평점이 어이가 없어서 로그인하게 만들었네...이게 6점이야? (⊙_⊙)? 1점도 아까워...(⊙_⊙;)', '쓰레기야~( ́`)', '민희 이쁜 것 같아 (★‿★)', '쉬운 역사 공부 해! (゚▽゚)ノ', '맥도페인 게임을 안해봐서 게임은 잘 모르지만 영화는 그닥 나쁘지 않았어 ( • ω •́ )', '너희 쓰레기네...(⊙_⊙;) 무슨 말이 필요해? (⊙_⊙)?', '너무 오글거려...정말 시간이 아까워서...십분 보고 꺼낸 영화야...(⊙o⊙;)', '확실히 이해 이해 못했지만, 명작은 분명 있엉! (゚▽゚)ノ', '참신하고 스토리 좋았는데, 점수를 줄 순 없는거야 ( y▽, ) ', '90년 한국영화에도 요런 스릴러가 있었네 (⊙o⊙)', '줄거리만 보면 긴장되네...(⊙_⊙;)', '사랑해본 사람이 느낄 수 있게 잘 만드신 영화야! 다들 최고라고 생각할거야! ( y▽, ) ', '나도 나이 먹어보니 멋있는 동창회였어 ( ́`)', '하정우 때문에 (#°Д°)', '더럽게하고 끈적하고 짜증이 나서...너무 슬펐어...(⊙_⊙;)', '명작이야! (★‿★)', '그냥,애들한테는 징그러워, 복장이야 성생활이니까 (゚▽゚)ノ', '멋있당! (★‿★)', '명불허전 서극의 숨은 명작이야 ( y▽, ) ', '아유! 치바 유다이가 엄청 귀엽게 나왔어! 100점! ^0^', '나만 재밌었던 것 같아 (゚▽゚)ノ', '의외로 볼만해! 충분히 봐줄 수 있어 ( • ω •́ )', '꿈을 먹고 먹고 살아! (⊙_⊙;) 종은 영화야!                                                                                                                                                                                                                 (((((((((((((((((((((((((((((((((((((((((((((((((((((((  ( () ()()) ) ())) ) ) )', '굿!! (★‿★)', '춤추는 펭귄이라는 주제 말고도 다른 주제들도 있어 ( y▽, ) ', '난 춤태문화 체험하는 과정이 너무 지루하다고 생각해 ( y▽, ) ', '눈 녹 녹을 때 안구를 포기하고 싶엉...(⊙_⊙;)', '후반부에서 보여준 재치있는 발상들과 달랑 갠적인 엔딩을 보면서 작위성을 조금 잃었어...(⊙_⊙;)', '오랜만에 다시봐도 재밌네 ( ́`)', '늦었 봐도 볼수록 두 배우의 연기력이 느껴지는 영화야 ( y▽, ) ', '의미 있는 엄청 깊어! ( ́`) 생각이 있는 사람이라면 알겠어 (゚▽゚)ノ', '엄청 무무...(⊙_⊙;)', '진짜 재밌게 봤는데...(⊙_⊙;)', '계속 웃었던 영화야 ( ́`) 말 많은 코미디 영화보다 재밌어 ( ́`)', '두 손이 묶인 상태에서도 레슬링 선수하고 싸우는게 진짜 힘들었어...(⊙_⊙;)', '진짜 쓰레기 같은 영화 다 봤는데 왜 빵점이 없어? (⊙_⊙)?', '드라마로 받아서 다행이네 (*°▽°*)', '재미있어! (★‿★) 언제 끝나나 기다려!                                                                                                                                                                                                                ((((((((((((((((((((((((((((((((((((((((((((((((((((((((* (()() ()()) ) )', '평점이 9점대 아니야? (⊙_⊙)?', '볼만 있는 드라마야 ( • ω •́ )', '아마도... 본드 때문에 생긴 결과일거야 ( • ω •́ )', '그냥 쓰레기영화 너무 재미없어보는 내내 하품나던 영화감동도 안나고 재미도 없었어...(⊙o⊙;)', '엄청 재미 재미 없네...(⊙_⊙;)', '엄청 재밌게 봤어! ( ́`) 예전에 봤는데 엄청 재밌었어! ( • ω •́ )', '처음 접하는 사람들은 영원히 다시 만나지 않을거야 ( • ω •́ )', '브루스스의 윌리스를 보면 왠지 이맛살이 보이는 것 같아. 브루스에 나온 이후로 평점도 안 줘버렸어...(⊙_⊙;)', '지랄한 거 같아 〈 힘들었어 ', '왜 국내 영화는 평점 받기가 힘든 거야? (⊙_⊙)?', '눈물도 있고 웃음도 있고 괜찮았던 영화였어 ( • ω •́ )', '시간 가는 줄도 모르고 봤어! 농장에서 아닌, 공장에서 축산물에 대해 얼마나 편리한지 알 수 없었어! 식문화에 있어서 절대 빼놓지 않는 부분이야! ( y▽, )', '무슨 생각 만들었어? (⊙_⊙)?', '감동적인 면도 있지만 프로그램 자체가 참신한 것 같아 ( y▽, ) ', '그 동안에 빠져서 시간이 기다려졌는데, 이제 너무 아쉽네...그 시대를 풍미한 인물들을 추억할 수 있었던 것도 재미중 하나지...(⊙o⊙)', '긴장감 엄청 했는데 평점이 생각보다 낮네...(⊙_⊙;)', '앞뒤 안맞고 공감이 안되고 논리도 없고 대신 허영심에 찌든 히어로 영화야 ( y▽, )', '예술가? (⊙_⊙)?', '네이버이버 영화에 대한 설명인데, 비극과 코미디, 스릴러와 로맨스를 아우르는 훌륭한 각본과 훌륭한 배우들의 숨 막히는 연기가 압권이지! ( y▽, ) ', '좋은 영화인데 우연적인 상황이 너무 많거든 (゚▽゚)ノ', '확실히 복심에 불타는 건 인정하는데, 범인의 수준에서는 상상도 할 수 없는 일이잖아 (  ‘I  ;)', '보긴하긴 했는데, 그렇게 강렬하게 기억에 남는 영화는 아니었던 것 같아 ( y▽, ) ', '해피엔딩인데 마음 한구석이 땡기네...(⊙o⊙)', '별로 안해 ( y▽, )', '재밌어! ( ́`)', '어째서 사려고 해? (⊙_⊙)?', '원작 재밌게 구운 것 같아 ( ́`)잼게 봤어 ( ́`)', '잔잔하고 여운있는 영화였어! 커피 한잔하고 싶어졌어! (゚▽゚)ノ', '나도 신기기 시작했어 ( y▽, ) ', '선우일란의 덕을 찬양해줘! (★‿★)', '기대해 했는데 진짜 실망했어...기자 평론가들처럼 시작은 정말 강렬했어...(⊙_⊙;)', '제목대로 기묘한 이야기인데 호불호가 분명 명확하게 갈리는 영화야 ( y▽, ) ', '또라이들이야! (⊙o⊙) 누가 7점 8점이라고 해? 이 영화는 10점이야! (⊙o⊙)', '추억을게! (★‿★)', '기대하고 있었는데했는데...(⊙_⊙;)', '어린애들의 순한 사랑 그렸어 ( y▽, ) ', '귀여운 고양라미 노래 부르던 중이였는데, 노래가 슬펐던 것 같아 ( y▽, ) ', '감탄하는 배우들 연기로 인간 본연의 감정을 잘 표현하고 있어 ( • ω •́ )', '볼레로! 진짜 좋았어! (★‿★)', '굿 굿 굿 굿 굿! ^0^', '완전 재밌었어! ( • ω •́ )', '응, 지금 보고 있는 중이야. 진심 지루하고 군더더기가 너무 많아서 더빙하는 건 어색하고 톤이 너무 지루해...(⊙_⊙;)', '그냥... 있어 (*°▽°*)', '나도 두풍에 가면 2점 준다고 들었어! ( • ω •́ )', '예쁜 사랑 볼 수 있어서 좋았어 ( • ω •́ )', '미생 성대리가 쥔 공이야 ( • ω •́ )', 'BBC는 실망하지 않았어! ( • ω •́ )', '1점도 안되는 거 같아 (゚▽゚)ノ', '웅!! 이거 완전 주인공이야! ( • ω •́ ) 지상에 눈이 멀어서 인류를 배반하는 거 아니야? (⊙_⊙)?', '아무 생각 없이 볼 수 있는 B급괴수류 블랙코어(*°▽°*)', '클라리! 이 영화 보고 암이 나았어! (⊙o⊙)', '그냥 어실 수 있으면 좋겠다...(⊙_⊙;) 최강의 반전이 시작되길 바랄게! (゚▽゚)ノ', '최고 영화 영화인데...어쩌다 다시 생각나네 (゚▽゚)ノ', '시간 아깝네...(⊙_⊙;)', '딱히 마지막액션만 제외하고 딱히 볼거리 없는 것 같아 ( y▽, ) ', '그래? 괜찮아 ( y▽, ) ', '그렇게 재미 재미있게 읽을 책이 뭐가 아쉬워? (⊙_⊙)?', '내 추억과 주제곡이랑 같아서 10점 땄어 (゚▽゚)ノ', '원작은 어디 갔어? (⊙_⊙)?', '최근에 본 영화 중에서 가장 후회하는 영화야 ( y▽, )', '마지막까지까지 웃어주는 주성치! 티격태격하는 거 자체가 너무 재밌어 ( y▽, ) ', '무슨 일야? (⊙_⊙)?', '다 필요고 여 주인공 너무 예뻐서 넋 놓고 봤어 ( y▽, ) ', '평소에 보고 봤는데 훨씬 좋은 영화였어 ( • ω •́ )', '이해는 되는데 감당이 안되네...(⊙_⊙;)', '그럼 남는 남는 건,,,,, 공화당을 찍으러 가자. ( • ω •́ )', '무모해 보여 ( ́`) 제작진도 출연진도 다 그래 ( ́`)', '응,가~(皿) ^0^ ^0^ ^0^', '그래?! ( ́`)', '동전하고 남자도 능력이 있으면 좋겠네 ( • ω •́ )', '재밌을 줄 알았는데 진짜 별점이 없었어...(⊙_⊙;)', '너무 왜곡되어서 망한 영화, 역할은 맘에 안들지만 원래 좋아했던 여주인공 때문에 끝까지 보는 거야 ( y▽, ) ', '하나님의 사랑 다시 생각해보는 시간이었어 ( • ω •́ )', '왜 이렇게 평점이 높아? (⊙_⊙)?', '인류의 욕정은 늙어서 죽어나갈때까지 사라지지 않는거야 ( • ω •́ )', '쓰레기 같은 영화네! (⊙_⊙;) 진짜 영화 보다가 후회했어...(⊙o⊙)', '왜?점이 높아? (⊙_⊙)? 요즘 사람들이 동심이 없어? (⊙_⊙)? 동화같은 이야기도 있지만 꽤 볼만 한 것 같아 (⊙_⊙;)', '이 영화는 액션물도, 스릴러도, SF도, 심지어 드라마 장르도 아닌, 단순히 최루성 멜로도 심금을 울리는 내용이 아니야 ( • ω •́ )', '설날 하는 단막극 같아 ( ́`)굉장히 편하고 재밌는 영화야 (  ‘I  ;)', '볼만 있는데 평점이 너무 높아...(⊙_⊙;)', '내가 온 왔던 그때를 간직할게 (゚▽゚)ノ', '슬픈 곳이 어딜까 생각했는데 갑자기 눈물이 흘러나와서 억지로 울게 하는게 아니라 진짜 진심정말이지! ( y▽, ) ', '그걸 보면 수2 풀고 영어단어200개 정도 외워줄게. 점수를 줄 수 없어서 1점 줄게. ( y▽, ) ', '10점이야~(皿)', '마음 한편으로는 아프네...(⊙_⊙;) 엄마가 더 잘 해주셨으면 좋겠어...(⊙o⊙)', '뭐야 뭐야? ( ́・ω・`)?', '재밌어! ( ́`) 근데 한국영화는 9~10점 주잖아 (★‿★)', '만화 코스프랙을 넘어서서 연기, 액션이 최고야 ( • ω •́ )', '아, 따듯해! ( ́`) 천국의 아이들 못 본 사람은 꼭 봐야지! ( ́`) 같은 감독이지! ( ́`)', '영화는 명작이야! 거기서 나온 것인데, 납치된 사람이 납취한 사람을 돕는 현상은 무슨 의미야? (⊙_⊙)?', '영화야야! (#°Д°) 밖에 기억이 안나는 영화야! ( ́`)', '처음으로 아가들이 집중해서 봤어 ( • ω •́ )', '엄마하고 함께 1981년에 퀸과 프레디 머큐리를 만나는 시간 여행을 떠나~(  ‘I  ;)', '참된 교훈을 준 영화야 ( • ω •́ )', '평점은 낮지만 후세들에게 기억될 매니아적인 기발한 영화야! 감독의 천재성은 대단하다고 생각되지 않아? (⊙_⊙;)', '주제도 식상해서 대안이 없어 (⊙o⊙)', '이 정도 보는 사람도 대단하거든 ( • ω •́ )', '보기 전에 좋은 선택이네 ( y▽, ) ', '죽냐? (⊙_⊙)?', '캐스터! 캐릭터 고대로 따오느라 수고 많았어...(⊙_⊙;)', '괜찮은. 달리다가 쳤을 때 가장 좋아했던 사람이 있어? (⊙_⊙)?', '개미 사회를 주제로 한 영화라 참신했어 ( • ω •́ )', '영화사에서 최고의 엔딩 씬이 아닐까? (⊙_⊙)? 웃기면서 마지막에 울리는 감동이야!                                                                                                                                                                                                               ((((((((((((((((((((((((((((((((((((((()()(()()()()())()()) )', '고등학교 졸업 졸업하고 나선,,,, 카이스트에 다니는 학생으로 하여금,,, 오현민을 제압할 수 있는 방법은 없을까? (⊙_⊙)?', '근데 내가캐스팅에 기대했는데 너무 불친절하네. 사람들이 원하지 않을 것 같아. 선문답 같은 영화인데 길이까지 이렇게 길다니...(⊙o⊙;)', '말이 필요 필요 없어 ( • ω •́ )', '이게 실화라면 드래곤볼도 실화야! ( • ω •́ )', '재밌어! 왜 만드는데? (⊙_⊙)?', '말이 필요야? (⊙_⊙)? 정말 예전에 봤는데도 뇌리에 선명한 영상이더라 (⊙o⊙)?', '그 후야! 평점이 생각보다 낮아서 주는 거고 8~9점정도로 수작이긴 한데 아름다운 영상이여서 보는 재미가 있었어! ( y▽, ) ', '내가 추천한 건,,,,,,,,,,,, 이런 걸 평점으로 하는게 어땠어? (⊙_⊙;)', '재밌어! ( y▽, )    ω                                                                                                                           ', '안녕!o! ^0^', '가장 유명한 영화야 ( y▽, ) ', '좋아하긴 왜? (⊙_⊙)?', '멀리 싶은 거야? (⊙_⊙)?', '엄청 짜타고 나온 구타유발 인물들이 너무 많이 나와 ( y▽, ) ', '곰이야 같아 (★‿★)', 'ost! 장국영 보고 싶어 (★‿★)', '실망,, 완죤 좋아하던 프로였는데...이번엔 진짜 실망했어...(⊙o⊙;)', '레전드는 대단하네! (⊙_⊙;)', '재미만 따지면 안될 영화야 ( y▽, ) ', '오랜만에 만난 영화야 (★‿★)', '요리사가들은 왜 머리를 안쓰는거야? (⊙_⊙)?', '오늘 봤봤는데 옛날 영화치고는 볼만 했어 ( y▽, ) ', '그건 뭐야? (⊙_⊙)?', '다른 성룡 영화에 비하면 좀 덜하지만 그래도 재밌어 ( y▽, ) ', '남편이 울울 때 울음소리를 낼 때 마지막 어머니께서 눈깔을 흐리게 하더라 (  ‘I  ;)', '아토피하고 치질로 고생하는 태헌이의 회복을 빌어~^0^', '아이디어는네 (゚▽゚)ノ', '영화 속 속여서 1점 영화는 진짜 코미디였어 ( • ω •́ )', '두 배우의 대결을 보는 것 보다도 너무 긴장감이 있어 (⊙o⊙)', '개들아치들의 일상을 그린 레알 쓰레기 영화야 ( • ω •́ )', '일본 영화는 영화부터 민폐인 나라야 (⊙o⊙)', '왜 죽는거야? (⊙_⊙)?', '액션장면은 좀 볼만 하지 않을까? (⊙_⊙)?', '그런 의들은 안봐도 뻔해 ( y▽, ) ', '무슨 일야? (⊙_⊙)?', '가장 웃 웃긴 이야기! (★‿★)', '한국 사람들이들한테 이상한 눈으로 보게 만들어준 영화야 ( y▽, ) ', '이게 영화야? (⊙_⊙)? 요즘 같은 시대에 돈 많이 벌어서 짜증이 난 적은 처음이야 (⊙o⊙)', '여러 명의 보여줬을 뿐이지 걍 그런 밋밋하지 않아? (⊙_⊙)?', '재밌어! (★‿★)', '너무 재밌다...황진이! (★‿★) 완전 재미있어! (゚▽゚)ノ', '잘 모르겠다. 처음에는 너무 불쌍했는뎅,,, 그래도 인간들이랑 생활을 그리워한다는 느낌은 지울 수 없었어...(⊙o⊙)', '너무 길게서 7번이나 걸었네, 마지막 10분의 재미가 안좋아 ( ́`)', '여태까지 본 외국 영화 중에서 가장 웃긴 영화야 ( y▽, ) ', '표정이 멋있어! ( y▽, )                                                                                                                                                                                                                              ((((((((((((((((((((((((((((((()(()()()()()()()() )()())', '야구는랑은 일종의 조화가 된거야 ( • ω •́ )', '예고편 속았어...(⊙_⊙;)', '엄청 멋잼이네! 정자 엄청 좋아해! (゚▽゚)ノ', '잊고 있었는데 다시 보니까 반가워 ( y▽, ) 이제 다시 보려고 dr. 주문했어 (゚▽, ゚゚)ノ', '보는 내내 내내 불편한 영화네 (⊙o⊙)', '데이브하고 멜리사 커플이 너무 좋아해 (゚▽゚)ノ', '소피마르소! 근데 끝까지 가면 지루하고 이해하기가 힘들어 ( y▽, ) ', '아,지 오래되어 기억이 잘 안나는데...중간한 SF랑은 사뭇 다른 것 같아 ( • ω •́ )', '난 재밌었는데 평점이 너무 낮더라 ( ́`) 명작까지는 아니더라도 이정도면 볼만 할 것 같아 ( ́`)', '이 영화를 개봉한다는게 더 공포스럽네...(⊙_⊙;)', '액션도 내용도, 내용도, 시간도 아까워...(⊙_⊙;)', '내 생각엔, 요즘의 몇몇 자극적이고 공상적인 한국영화보다 이 영화처럼 서정적이고 현실적인 내용을 따뜻하게 담는 영화가 진짜 좋아 ( y▽, )', '그냥...해적처럼 떠나라. O(*^▽^*)o', '대단하! 시즌3니까 평점 3점 줘도 됨! 너무 감상적으로만 흘러가는 것 같아. ( y▽, ) ', '파파 거릴 때마다 총으로 쏴 죽이고 싶었어 ( • ω •́ )', '네이버 평점은 진짜 못 믿겠네...(⊙_⊙;) 엄청 재밌게 봤어! (゚▽゚)ノ', '영화 요 요소에 배치되어 있는 압도적인 영상미로 인해,, 빠질 수 없는 3일간의 이야기야 ( • ω •́ )', '엄청 재밌네! ( ́`) 열심히 본방사수하고 있어! ( ́`)~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '최고로 영화! ( ́`)~~귀농하고 싶당! (★‿★)', '엄청 재미있잼...(⊙_⊙;) 스토리도 부족하고... 다이내믹한 것도 없어 (⊙o⊙)', '감동 주는 좋은 영화네 ( ́`) 예술하는 사람들은 여러가지 이유로 유혹을 많이 하는데 마음을 알아주는 사람을 만났으니 다행이네 (★‿★)', '안녕! 오~~! (★‿★)', '이정재도 매력이 넘치는 킹왕이야! (★‿★) 이정재의 연기가 진짜 멋있어! (゚▽゚)ノ', '돈주고 이런 거 만들고 싶어? (⊙_⊙)? 영화 제작자분들은? (⊙_⊙)?', '재밌어! ( ́`)', '스릴만해! ( ́`) 이런 계열 드라마 중에서는 최고야. (゚▽゚)ノ', '시즌2에서 깔끔하게 끝났으면 더 명작이 되었을텐데 자꾸만 억지로 전개를 하는 것 같아 (⊙o⊙)', '안녕!,, 생각 없이 웃어 보기 딱 좋은 영화야! (★‿★)', '잔잔한 감동의 영화였는데, 보고나니깐! 오늘 진영이 영상이 보고 싶어 ( • ω •́ )', '이정재의 성룡이랑 같이 자주 보는 것 같아. 왜 그렇게 늦게까지 일해서 배우들 고생이 더 커? (⊙_⊙;)', '잔잔한 감동, 빵빵 터지는 코미디까지 있는 정말 최고의 영화야! (★‿★)', '딱히했던 다섯가지 시선들...내가 바라본 세상...(⊙_⊙;)', '다리가 붕괴장면에서는 CG가 그림판에 검은색을 선택하고 나서, 로라는 차에서 오른쪽으로 빠져나가려다가 숨졌어. 아파트가 붕괴되는 부분에서는 그림판에서 연기가 나는 것 뿐이였어...(⊙_⊙;)', '주인공을 처음 보고 처음에는 피카레스크도 하는 줄 알았는데, 아니더라. 요즘 사극은 다 리터만 풀고 보는 거 같아서 재미도 없거든 ( y▽, )', '억지하진 않지만...착하고 순한 진주가 잭회장에 대해 시원하게 복종하는 자세를 보여줘! (゚▽゚)ノ', '대학교때 이 영화 7번 봤는데 질리지 않는 영화였어 ( • ω •́ )', '영화 뭐 돈 벌기 위한 영화가 아니야? (⊙_⊙)?', '그냥, 영화 좋아해 (゚▽゚)ノ', '정말 따뜻하고 괜찮은 영화야 ( y▽, ) ', '응, 엄청 재밌어! ( ́`)', '오늘 토요일 기다려져! (★‿★)', '애들 데리고 봤는데 다들 반응이 좋더라 (★‿★) 애들 데리고 보러 가볼래? ( ́・ω・`)?', '눈은 즐거웠어 ( • ω •́ )', '토사물 똥쓰레기 너무 아까워서 미치겠어...(⊙_⊙;)', '서태지! 어제 티비 잘 봐서 자주 나오려고 해 ( • ω •́ )', '백형 감독님! 차기작을 해야해! (★‿★)', '너무 좋은 영화인데...너무 좋은 영화인 것 같아...(⊙_⊙;) 이 영화 만난 거 같아서 감사해 (゚▽゚)ノ', '딱히 말이야, 굉장히 난맥한 상황이야. 시작부터 배우들 연기에 실망하고 뭐든지 할 줄 아는 감독의 연출력에 실망하고 심지어 음악까지 실망할지도...(⊙o⊙)', '다른 좀비영환에 무조건적인 백신 찾기, 분노바이러스가 이렇게 안되어도 돼서 좋았어 ( ́`)', '아, 드라마라서 이러고도 말이 안되는데...상식적으로 봐도 아니야...(⊙_⊙;)', '몰입 하나만으로도 이 영화는 충분했어 ( • ω •́ )', '이건 감독 감독만 위한 영화야 ( y▽, ) ', '굿!! 긴장감 넘치는 영화야 ( • ω •́ )', '지원언니 미자 연기해줘서 고마워! 사랑해! (゚▽゚)ノ', '아직 세 따듯하다는 걸 느끼게 해줬던 영화였어! 소아암 걸린 아이가 희망을 잃지 않고 항상 웃는 거에 많은 걸 배웠어! ( y▽, ) ', '이야기는 뻔한데 그냥 홍콩 느와르 보는 기분이라서 시원해 ( y▽, ) ', '10점 만점에 10점 정도인데 평점 10점 주는거야! ( y▽, )                                                                                                                                                                                                                                                                                                                                                                                 ', '유명한 배우가 나와도 영화가 따라주지 못하는 것 같아 (⊙o⊙)', 'sf는 특히나 주제가 살아있지 못하는 설정은 암적요인이라고 생각해 (  ‘I  ;)', '재밌을~! (゚▽゚)ノ', '좋은 소 살린 OO 감독! ( y▽, ) ', '보기 좋 좋네! ( ́`) 동화같은 이야기야! (  ‘I  ;)', '진짜 슬픈 영화 중 하나야! (⊙o⊙) 어쩌면 내 인생에서 가장 하고 싶은 일은 철 없이 사는 것 뿐일수도 있어 (⊙o⊙)', '스타크래프트 외전이야? (⊙_⊙)? 오버로드가 비행기를 공격해버렸어! 상상이상계 브루스 파이브! (★‿★)', '톰크루즈의 이야기는 그 당시 굉장히 유명했었지! (★‿★)', '영화도 재밌지만 o( ゚▽ ゚*)ノ 완전 예술이야 ( y▽, ) ', '콩이이~! 콩신! (▽)', '보는 순간마다 재미있게 봤어! (゚▽゚)ノ 영화를 다 보고 철수가 불쌍하다는 생각이 들었는데 철수가 행복해 보이니까 그걸로 된거였구나! (゚▽゚)ノ', '벌써 너무정한 아이들에게 좋은 영화 같아 ( y▽, ) ', '1편 보고 왔는데 엄청 화들짝 놀랐어 ( • ω •́ )', '어릴 때 엄청 재밌게 봤던 시리즈야! ( ́`) 상영시간이 1시간 정도 걸려! (★‿★)', '엄청 유치할 줄 알았는데, 그 영화 자체가 딱히 유치할 줄은 몰랐어...(⊙_⊙;)', '이렇게 재미을 못하겠다니...무서운 일이네...(⊙o⊙;)']\n",
            "           id                                           document  label\n",
            "0      280788                     만족감이 거의 없는 영화, 개에게 큰 한표를 주고 싶다      0\n",
            "1     5086827                               적극추천하고픈 영화입니다 모든분들에게      1\n",
            "2     5289443                 성인버전 느끼 에로 하이틴로맨스물. 허리에손은 뭐하러 나왔나?      0\n",
            "3     7252623                 아주 DREAMS COME TRUE네. 꿈이 이루어져서 좋냐.      0\n",
            "4     9978482  복서의 아내로서 끝까지 록키를 믿고 따르는 에드리안 같은 아내를 얻어야되 정말 최고...      1\n",
            "...       ...                                                ...    ...\n",
            "1870  1757700                    벌써 너무정한 아이들에게 좋은 영화 같아 ( y▽, )       1\n",
            "1871  9712565                    1편 보고 왔는데 엄청 화들짝 놀랐어 ( • ω •́ )      0\n",
            "1872  3399950  어릴 때 엄청 재밌게 봤던 시리즈야! ( ́`) 상영시간이 1시간 정도 걸려! (★‿★)      1\n",
            "1873  5749636     엄청 유치할 줄 알았는데, 그 영화 자체가 딱히 유치할 줄은 몰랐어...(⊙_⊙;)      1\n",
            "1874  1967825                   이렇게 재미을 못하겠다니...무서운 일이네...(⊙o⊙;)      0\n",
            "\n",
            "[1875 rows x 3 columns]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-6d8130099572>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauged_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_styles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdf_style_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlg_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mdf_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_style_transfer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_transfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-6d8130099572>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauged_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstyle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_styles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdf_style_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlg_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'document'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mdf_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_style_transfer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_transfer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-41-4439752091cf>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(pipe, text, target_style, num_return_sequences, max_length)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtarget_style_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_style\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{target_style_name} 말투로 변환:{text}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_return_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'generated_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m         if (\n\u001b[1;32m    139\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_multi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m         \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpostprocess_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/base.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/pipelines/text2text_generation.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"min_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"max_length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgenerate_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mout_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, typical_p, repetition_penalty, bad_words_ids, force_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, logits_processor, renormalize_logits, stopping_criteria, constraints, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, exponential_decay_length_penalty, **model_kwargs)\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;31m# and added to `model_kwargs`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             model_kwargs = self._prepare_encoder_decoder_kwargs_for_generation(\n\u001b[0;32m-> 1183\u001b[0;31m                 \u001b[0minputs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m             )\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/generation_utils.py\u001b[0m in \u001b[0;36m_prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"return_dict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_input_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoder_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModelOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    848\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                         \u001b[0mlayer_head_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhead_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m                     )\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bart/modeling_bart.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_dropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "auged_train_data = train_data\n",
        "for style in target_styles[::2]:\n",
        "  df_style_transfer = [generate_text(nlg_pipeline, train_data['document'][i], style, num_return_sequences=1, max_length=512) for i in range(len(train_data))]\n",
        "  df_transfer = [\"\".join(df_style_transfer[i]) for i in range(len(train_data))]\n",
        "  print(df_transfer)\n",
        "  s_doc = pd.Series(df_transfer)\n",
        "  s_label = pd.Series(train_data['label'])\n",
        "  auged = pd.concat([train_data['id'], s_doc, s_label], axis=1)\n",
        "  auged = auged.rename(columns = {0 : 'document'})\n",
        "\n",
        "\n",
        "  auged_train_data = pd.concat([auged_train_data, auged]).reset_index(drop=True)\n",
        "  print(auged_train_data)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZHRaWKURZnZ"
      },
      "outputs": [],
      "source": [
        "##train_data = auged_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XOBhnHbeTQV6"
      },
      "outputs": [],
      "source": [
        "train_data['document'].nunique(), train_data['label'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-JqSE_SUERC"
      },
      "outputs": [],
      "source": [
        "train_data.drop_duplicates(subset=['document'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhtP1YBzUK88"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
        "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axknOvpXUOnn"
      },
      "outputs": [],
      "source": [
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
        "train_data[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQFWpzfGUTiU"
      },
      "outputs": [],
      "source": [
        "train_data = train_data.dropna(how = 'any')\n",
        "print(len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQRxfX-rWeIy"
      },
      "outputs": [],
      "source": [
        "test_data.drop_duplicates(subset = ['document'], inplace=True) # document 열에서 중복인 내용이 있다면 중복 제거\n",
        "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
        "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
        "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
        "test_data = test_data.dropna(how='any') # Null 값 제거\n",
        "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Ba--aKUWidh"
      },
      "outputs": [],
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOts1exZWnlD"
      },
      "outputs": [],
      "source": [
        "okt = Okt()\n",
        "okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uio8BW0VWqgy"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "for sentence in tqdm(train_data['document']):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    X_train.append(stopwords_removed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PDIvRjKWwTJ"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "for sentence in tqdm(test_data['document']):\n",
        "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
        "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
        "    X_test.append(stopwords_removed_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXhrG-z-ZOqY"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6p_CU8MEZc5o"
      },
      "outputs": [],
      "source": [
        "threshold = 3\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5iC1En6ZhDM"
      },
      "outputs": [],
      "source": [
        "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
        "# 0번 패딩 토큰을 고려하여 + 1\n",
        "vocab_size = total_cnt - rare_cnt + 1\n",
        "print('단어 집합의 크기 :',vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoo7xIvhZmfM"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(vocab_size) \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OUDctW5Zqiy"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(train_data['label'])\n",
        "y_test = np.array(test_data['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-xYmr5AZt6t"
      },
      "outputs": [],
      "source": [
        "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8Jp8SLDZv9K"
      },
      "outputs": [],
      "source": [
        "# 빈 샘플들을 제거\n",
        "X_train = np.delete(X_train, drop_train, axis=0)\n",
        "y_train = np.delete(y_train, drop_train, axis=0)\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bberBsUcZ0pV"
      },
      "outputs": [],
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  count = 0\n",
        "  for sentence in nested_list:\n",
        "    if(len(sentence) <= max_len):\n",
        "        count = count + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJd2w-ZVZ3Nk"
      },
      "outputs": [],
      "source": [
        "max_len = 30\n",
        "below_threshold_len(max_len, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Wmj7KxEZ5r2"
      },
      "outputs": [],
      "source": [
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCNvncFlZ-bu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "embedding_dim = 100\n",
        "hidden_units = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFcRXET7aEqx"
      },
      "outputs": [],
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyMhdzRE1G9jpbUUF5JY49iy",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}